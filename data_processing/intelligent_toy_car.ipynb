{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://githubtocolab.com/bijanmehr/Intelligent_toy_car/blob/data_processing/toy_car_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QXnDtyBYgCZ"
      },
      "outputs": [],
      "source": [
        "import  pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "import scipy.fft as sc\n",
        "import scipy.signal as scs\n",
        "import warnings\n",
        "import sklearn.svm as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlHmcmQ9YmFL"
      },
      "outputs": [],
      "source": [
        "#read the csv file\n",
        "data = pd.read_csv(r'C:\\PythonCode\\website_toycar.csv')   \n",
        "print (data)\n",
        "\n",
        "#define data in numpy to be able to work with\n",
        "A= np.array(data)  \n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpiiZpABYuNK"
      },
      "outputs": [],
      "source": [
        "#function for Plotting one curve, a=0 or 1 sets label\n",
        "def plot1ac(t, x, name, a):\n",
        "    if a==0:\n",
        "        plt.plot(t, x, label='before denoising')\n",
        "    else :\n",
        "        plt.plot(t, x, label='after denoising')\n",
        "    plt.xlabel(\"time (millisecond)\")\n",
        "    plt.ylabel(\"Acceleration\") \n",
        "    plt.title(name)\n",
        "    plt.legend() \n",
        "    return plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKtBD7EYY9FV"
      },
      "outputs": [],
      "source": [
        "def madev(d, axis=None):\n",
        "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
        "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Esj710AY-NB"
      },
      "outputs": [],
      "source": [
        "#function for denoising\n",
        "def wavelet_denoising(x, wavelet='db4', level=1):\n",
        "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
        "    sigma = (1/0.6745) * madev(coeff[-level])\n",
        "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
        "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
        "    # aaa=pywt.waverec(coeff, wavelet, mode='per')\n",
        "    # plt.plot(aaa, label='after denoising')\n",
        "    # plt.legend() \n",
        "    # plt.show()\n",
        "    return pywt.waverec(coeff, wavelet, mode='per')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roTwD4O0ZBPv"
      },
      "outputs": [],
      "source": [
        "#function for fourier transform, with negative amounts\n",
        "def fftfunction1(signal, duration, N, name):\n",
        "    yf= sc.fft(signal)\n",
        "    xf= sc.fftfreq(N, N//duration)\n",
        "    plt.plot(xf, np.abs(yf))\n",
        "    plt.title(name)\n",
        "    return plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO67aTvQZDqZ"
      },
      "outputs": [],
      "source": [
        "#function for fourier transform, without negative amounts \n",
        "def fftfunction(signal, duration, N, name):\n",
        "    y0f= sc.fft(signal)\n",
        "    yf= 2.0/N *np.abs(y0f[0:N//2])\n",
        "    xf= sc.fftfreq(N, N//duration)[:N//2]  #should be duration//n but no answer!because time/1000!\n",
        "    #plt.plot(xf, yf)\n",
        "    #plt.title(name)\n",
        "    #plt.show()\n",
        "    return xf,yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "932d30hBZJs8"
      },
      "outputs": [],
      "source": [
        "def alltop5points(dx,dy,dz,t):\n",
        "    xx, yx=fftfunction(dx, t[len(t)-1], len(t), 'ac_x')\n",
        "    xy, yy=fftfunction(dy, t[len(t)-1], len(t), 'ac_y')\n",
        "    xz, yz=fftfunction(dz, t[len(t)-1], len(t), 'ac_z')\n",
        "    a1=top5points(xx,yx)\n",
        "    a2=top5points(xy,yy)\n",
        "    a3=top5points(xz,yz)\n",
        "    A=np.concatenate((a1[:,1], a2[:,1], a3[:,1],a1[:,0], a2[:,0], a3[:,0]))\n",
        "    #[:,1]=amplitude in top points,[:,2]=frequency in top points\n",
        "    return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMAYY2YGZM2_"
      },
      "outputs": [],
      "source": [
        "#finction for finding frequency and amplitude of top 5 points\n",
        "def top5points(xf,yf):    \n",
        "    #finding index of local maximums\n",
        "    index= np.array(scs.argrelextrema(yf, np.greater))\n",
        "    index= np.transpose(index)\n",
        "    localmax=np.zeros((len(index),2))\n",
        "    for i in range(0,len(index)):\n",
        "        localmax[i,0]=xf[index[i]]\n",
        "        localmax[i,1]=yf[index[i]]    \n",
        "    #sorting local maximums\n",
        "    sortlocalmax = localmax[localmax[:,1].argsort()]\n",
        "    top6localmax=np.delete(sortlocalmax, np.s_[0:len(index)-6], axis = 0)\n",
        "    #remonve zero frequency\n",
        "    top5localmax=np.delete(top6localmax, 5, axis = 0)\n",
        "    return top5localmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4lRrtJeZPhK"
      },
      "outputs": [],
      "source": [
        "#function for finding energy of signals in 2 ways: with or without zero frequency\n",
        "def allenergy(dx,dy,dz):\n",
        "    fx, Px=scs.welch(dx)\n",
        "    fy, Py=scs.welch(dy)\n",
        "    fz, Pz=scs.welch(dz)\n",
        "    # plt.plot(f,Px)\n",
        "    # plt.show()\n",
        "    # # plot with y-axis in log scaling\n",
        "    # plt.semilogy(f, Pxx_den)\n",
        "    # plt.xlabel('frequency [Hz]')\n",
        "    # plt.ylabel('PSD [V**2/Hz]')\n",
        "    # plt.show()\n",
        "    Emean1=[np.mean(Px), np.mean(Py), np.mean(Pz)] #Energy with zero frequency   \n",
        "    Pxx=np.delete(Px, [0,1,2,3,4,5,6,7,8])\n",
        "    Pyy=np.delete(Py, [0,1,2,3,4,5,6,7,8])\n",
        "    Pzz=np.delete(Pz, [0,1,2,3,4,5,6,7,8])\n",
        "    Emean2=[np.mean(Pxx), np.mean(Pyy), np.mean(Pzz)] #Energy without zero frequency\n",
        "    return Emean1 #output is Energy with zero frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksVnZektZSuH"
      },
      "outputs": [],
      "source": [
        "#function for finding energy of signals in 2 ways: with or without zero frequency\n",
        "def allenergy2(dx,dy,dz):\n",
        "    fx, Px=scs.welch(dx)\n",
        "    fy, Py=scs.welch(dy)\n",
        "    fz, Pz=scs.welch(dz)\n",
        "    # plt.plot(f,Px)\n",
        "    # plt.show()\n",
        "    # # plot with y-axis in log scaling\n",
        "    # plt.semilogy(f, Pxx_den)\n",
        "    # plt.xlabel('frequency [Hz]')\n",
        "    # plt.ylabel('PSD [V**2/Hz]')\n",
        "    # plt.show()\n",
        "    Emean1=[np.mean(Px)/2, np.mean(Py)/2, np.mean(Pz)/2] #Energy with zero frequency   \n",
        "    Pxx=np.delete(Px, [0,1,2,3,4,5,6,7,8])\n",
        "    Pyy=np.delete(Py, [0,1,2,3,4,5,6,7,8])\n",
        "    Pzz=np.delete(Pz, [0,1,2,3,4,5,6,7,8])\n",
        "    Emean2=[np.mean(Pxx), np.mean(Pyy), np.mean(Pzz)] #Energy without zero frequency\n",
        "    return Emean1 #output is Energy with zero frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VCYqAvZZlPJ"
      },
      "outputs": [],
      "source": [
        "def correlation(dx,dy,dz):\n",
        "    coxy=np.corrcoef(dx, dy)\n",
        "    coxz=np.corrcoef(dx, dz)\n",
        "    coyz=np.corrcoef(dy, dz)\n",
        "    allcorr=[coxy[0,1], coxz[0,1], coyz[0,1]] \n",
        "    return allcorr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR1a4dj6Znmt"
      },
      "outputs": [],
      "source": [
        "#function for short time fourier transform\n",
        "def stftfunction(signal, name):\n",
        "    f, t, Zxx = scs.stft(signal,nperseg=8) #64,128,256 v#8\n",
        "    plt.pcolormesh(t, f/0.5 , np.abs(Zxx))\n",
        "    plt.title(name)\n",
        "    plt.ylabel('Normalized Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "    return f, t, Zxx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIpEUqf8Zpe7"
      },
      "outputs": [],
      "source": [
        "#function for jolt Recognition in x axis\n",
        "def jolt(signalx, name):\n",
        "    f, t, Zxx= stftfunction(signalx, name)    \n",
        "    stftmean= np.mean(np.abs(Zxx), axis=0)\n",
        "    stftmean_normalized= stftmean/np.max(stftmean)\n",
        "    plt.plot(stftmean_normalized)\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "    j=np.std(stftmean_normalized)\n",
        "    return j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT5qAazRZrRP"
      },
      "outputs": [],
      "source": [
        "#function for jerk Recognition\n",
        "def jerk(signalx, name):\n",
        "    f, t, Zxx= stftfunction(signalx, name)\n",
        "    Zxx_new=np.abs(Zxx)\n",
        "    Zxx_new[Zxx_new < 10]= 0\n",
        "    stftmean= np.mean(np.nonzero(Zxx_new), axis=0)\n",
        "    stftmean_normalized= stftmean/np.max(stftmean)\n",
        "    plt.plot(stftmean_normalized)\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "    j=np.std(stftmean_normalized)\n",
        "    return j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SERsl3viZuZ_"
      },
      "outputs": [],
      "source": [
        "print('label 89')\n",
        "A89 = A[A[:, 7] == 89, :]\n",
        "#extract all rows with the 8th column 89 \n",
        "#print (A89)\n",
        "bias89=A89[0,1]\n",
        "#bias in  time scale that should be subtracted  \n",
        "for i in range(0,len(A89)):\n",
        "    A89[i,1]=A89[i,1]-bias89   \n",
        "#print (A89)\n",
        "x89time= A89[:,1]/1000\n",
        "y89ac=[A89[:,2], A89[:,3], A89[:,4]] #ac_x, ac_y, ac_z\n",
        "y89encoder= [A89[:,5],A89[:,6]]  #encoder1, encoder2\n",
        "plot1ac(x89time, y89ac[0],89 ,0) #see the signal before denoising\n",
        "dy89ac_x=wavelet_denoising(y89ac[0])\n",
        "dy89ac_y=wavelet_denoising(y89ac[1])\n",
        "dy89ac_z=wavelet_denoising(y89ac[2])\n",
        "F89=alltop5points(dy89ac_x, dy89ac_y, dy89ac_z, x89time) #feature vector=FV\n",
        "F89=np.concatenate((F89,allenergy(dy89ac_x, dy89ac_y, dy89ac_z))) #add energy to FV\n",
        "F89=np.concatenate((F89,correlation(dy89ac_x, dy89ac_y, dy89ac_z))) #add correlation coefficients to FV\n",
        "F89=np.append(F89,[jolt(dy89ac_x, '89')])#add xjolt to FV\n",
        "F89=np.append(F89,[6])\n",
        "F89=np.append(F89,[jolt(dy89ac_y, '89')])#add yjolt to FV\n",
        "F89=np.append(F89,[4])\n",
        "F89=np.append(F89,[x89time[len(x89time)-1]]) #add time feature\n",
        "#Zxxnew=np.abs(Zxx)\n",
        "# plot1ac(x89time, y89encoder[0], 89 ,0)\n",
        "# plot1ac(x89time, y89encoder[1], 89 ,0)\n",
        "y89encoder=np.array(y89encoder)\n",
        "newen=np.diff(y89encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "# plt.plot(newen[0])\n",
        "# plt.ylabel(\"encoder\") \n",
        "# plt.legend() \n",
        "# plt.show()\n",
        "F89=np.append(F89,[np.sum(newen)]) #add total number of turns\n",
        "F89=np.append(F89,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "#F89=np.append(F89,[np.sum(newen)/x89time[len(x89time)-1]]) #add total number of turns in time\n",
        "F89=np.append(F89,[len(newen[newen > 0])/x89time[len(x89time)-1]]) #add number of chnages in time\n",
        "F89=np.append(F89,[0,89]) #label normal\n",
        "F89=np.append(F89,[jolt(dy89ac_z, '89z')])#add yjolt to FV\n",
        "F89=np.append(F89,[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHw17BJ8aCfK"
      },
      "outputs": [],
      "source": [
        "print('label 94')\n",
        "A94 = A[A[:, 7] == 94, :]\n",
        "bias94=A94[0,1]\n",
        "for i in range(0,len(A94)):\n",
        "      A94[i,1]=A94[i,1]- bias94    \n",
        "#print (A94)\n",
        "x94time= A94[:,1]/1000\n",
        "y94ac=[A94[:,2], A94[:,3], A94[:,4]] \n",
        "y94encoder= [A94[:,5],A94[:,6]]\n",
        "# plot1ac(x94time, dy94ac_x,94 , 1)\n",
        "dy94ac_x=wavelet_denoising(y94ac[0])\n",
        "dy94ac_y=wavelet_denoising(y94ac[1])\n",
        "dy94ac_z=wavelet_denoising(y94ac[2])\n",
        "F94=alltop5points(dy94ac_x, dy89ac_y, dy94ac_z, x94time) #feature vector=FV\n",
        "F94=np.concatenate((F94,allenergy(dy94ac_x, dy94ac_y, dy94ac_z))) #add energy to FV\n",
        "F94=np.concatenate((F94,correlation(dy94ac_x, dy94ac_y, dy94ac_z))) #add correlation coefficients to FV\n",
        "F94=np.append(F94,[jolt(dy94ac_x, '94')])#add xjolt to FV\n",
        "F94=np.append(F94,[9]) #8\n",
        "F94=np.append(F94,[jolt(dy94ac_y, '94')])#add yjolt to FV\n",
        "F94=np.append(F94,[6])\n",
        "F94=np.append(F94,[x94time[len(x94time)-1]])\n",
        "y94encoder=np.array(y94encoder)\n",
        "newen=np.diff(y94encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F94=np.append(F94,[np.sum(newen)]) #add total number of turns\n",
        "F94=np.append(F94,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F94=np.append(F94,[len(newen[newen > 0])/x94time[len(x94time)-1]])\n",
        "F94=np.append(F94,[0,94])\n",
        "F94=np.append(F94,[jolt(dy94ac_z, '94z')])#add yjolt to FV\n",
        "F94=np.append(F94,[6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IGBQzvIaG8P"
      },
      "outputs": [],
      "source": [
        "print('label 95')\n",
        "A95 = A[A[:, 7] == 95, :] \n",
        "ChangeLocation=0\n",
        "#find the location of change in the timescale\n",
        "for i in range(0,len(A95)):\n",
        "    if A95[i,1] == 1594:# 1594= initial value of timer        \n",
        "        ChangeLocation=i        \n",
        "#print(ChangeLocation)     \n",
        "#print(A95[ChangeLocation-1,1])\n",
        "biastime=A95[ChangeLocation-1,1]\n",
        "for i in range(ChangeLocation,len(A95)):\n",
        "      A95[i,1]=A95[i,1]+ biastime\n",
        "biasEn1=A95[ChangeLocation-1,5]\n",
        "for i in range(ChangeLocation,len(A95)):\n",
        "      A95[i,5]=A95[i,5]+ biasEn1\n",
        "biasEn2=A95[ChangeLocation-1,6]\n",
        "for i in range(ChangeLocation,len(A95)):\n",
        "      A95[i,6]=A95[i,6]+ biasEn2 \n",
        "bias95En1=A95[0,5]\n",
        "for i in range(0,len(A95)):\n",
        "      A95[i,5]=A95[i,5]- bias95En1   \n",
        "bias95En2=A95[0,6]\n",
        "for i in range(0,len(A95)):\n",
        "      A95[i,6]=A95[i,6]- bias95En2\n",
        "bias95=A95[0,1]\n",
        "for i in range(0,len(A95)):\n",
        "      A95[i,1]=A95[i,1]- bias95\n",
        "#print (A95)\n",
        "x95time= A95[:,1]/1000\n",
        "y95ac=[A95[:,2], A95[:,3], A95[:,4]] \n",
        "y95encoder= [A95[:,5],A95[:,6]]\n",
        "dy95ac_x=wavelet_denoising(y95ac[0])\n",
        "dy95ac_y=wavelet_denoising(y95ac[1])\n",
        "dy95ac_z=wavelet_denoising(y95ac[2])\n",
        "F95=alltop5points(dy95ac_x, dy89ac_y, dy95ac_z, x95time) \n",
        "F95=np.concatenate((F95,allenergy(dy95ac_x, dy95ac_y, dy95ac_z))) \n",
        "F95=np.concatenate((F95,correlation(dy95ac_x, dy95ac_y, dy95ac_z)))\n",
        "F95=np.append(F95,[jolt(dy95ac_x, '95')])\n",
        "F95=np.append(F95,[4])\n",
        "F95=np.append(F95,[jolt(dy95ac_y, '95')])\n",
        "F95=np.append(F95,[6])\n",
        "F95=np.append(F95,[x95time[len(x95time)-1]])\n",
        "y95encoder=np.array(y95encoder)\n",
        "newen=np.diff(y95encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F95=np.append(F95,[np.sum(newen)]) #add total number of turns\n",
        "F95=np.append(F95,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F95=np.append(F95,[len(newen[newen > 0])/x95time[len(x95time)-1]])\n",
        "F95=np.append(F95,[1,95]) #label autistic \n",
        "F95=np.append(F95,[jolt(dy95ac_z, '95z')])\n",
        "F95=np.append(F95,[6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6Xxzp7maLWx"
      },
      "outputs": [],
      "source": [
        "print('label 100')\n",
        "A100 = A[A[:, 7] == 100, :]\n",
        "bias100=A100[0,1]\n",
        "for i in range(0,len(A100)):\n",
        "      A100[i,1]=A100[i,1]- bias100    \n",
        "#print (A100)\n",
        "x100time= A100[:,1]/1000\n",
        "y100ac=[A100[:,2], A100[:,3], A100[:,4]] \n",
        "y100encoder= [A100[:,5], A100[:,6]]\n",
        "dy100ac_x=wavelet_denoising(y100ac[0])\n",
        "dy100ac_y=wavelet_denoising(y100ac[1])\n",
        "dy100ac_z=wavelet_denoising(y100ac[2])\n",
        "F100=alltop5points(dy100ac_x, dy89ac_y, dy100ac_z, x100time) \n",
        "F100=np.concatenate((F100,allenergy(dy100ac_x, dy100ac_y, dy100ac_z))) \n",
        "F100=np.concatenate((F100,correlation(dy100ac_x, dy100ac_y, dy100ac_z))) \n",
        "F100=np.append(F100,[jolt(dy100ac_x, '100')])\n",
        "F100=np.append(F100,[6])\n",
        "F100=np.append(F100,[jolt(dy100ac_y, '100')])\n",
        "F100=np.append(F100,[8]) #6\n",
        "F100=np.append(F100,[x100time[len(x100time)-1]])\n",
        "y100encoder=np.array(y100encoder)\n",
        "newen=np.diff(y100encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F100=np.append(F100,[np.sum(newen)]) #add total number of turns\n",
        "F100=np.append(F100,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F100=np.append(F100,[len(newen[newen > 0])/x100time[len(x100time)-1]])\n",
        "F100=np.append(F100,[1,100])\n",
        "F100=np.append(F100,[jolt(dy100ac_z, '100z')])\n",
        "F100=np.append(F100,[8]) #6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PvwYvjNaQBp"
      },
      "outputs": [],
      "source": [
        "print('label 102')\n",
        "A102 = A[A[:, 7] == 102, :] \n",
        "bias102=A102[0,1]\n",
        "for i in range(0,len(A102)):\n",
        "      A102[i,1]=A102[i,1]- bias102    \n",
        "#print (A102)\n",
        "x102time= A102[:,1]/1000\n",
        "y102ac=[A102[:,2], A102[:,3], A102[:,4]] \n",
        "y102encoder= [A102[:,5], A102[:,6]]\n",
        "dy102ac_x=wavelet_denoising(y102ac[0])\n",
        "dy102ac_y=wavelet_denoising(y102ac[1])\n",
        "dy102ac_z=wavelet_denoising(y102ac[2])\n",
        "F102=alltop5points(dy102ac_x, dy89ac_y, dy102ac_z, x102time) \n",
        "F102=np.concatenate((F102,allenergy(dy102ac_x, dy102ac_y, dy102ac_z))) \n",
        "F102=np.concatenate((F102,correlation(dy102ac_x, dy102ac_y, dy102ac_z)))  \n",
        "F102=np.append(F102,[jolt(dy102ac_x, '102')])\n",
        "F102=np.append(F102,[4])\n",
        "F102=np.append(F102,[jolt(dy102ac_y, '102')])\n",
        "F102=np.append(F102,[2])\n",
        "F102=np.append(F102,[x102time[len(x102time)-1]])\n",
        "y102encoder=np.array(y102encoder)\n",
        "newen=np.diff(y102encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F102=np.append(F102,[np.sum(newen)]) #add total number of turns\n",
        "F102=np.append(F102,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F102=np.append(F102,[len(newen[newen > 0])/x102time[len(x102time)-1]])\n",
        "F102=np.append(F102,[0,102])\n",
        "F102=np.append(F102,[jolt(dy102ac_z, '102z')])\n",
        "F102=np.append(F102,[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM5JC5lEaSR9"
      },
      "outputs": [],
      "source": [
        "print('label 106')\n",
        "A106 = A[A[:, 7] == 106, :] \n",
        "bias106=A106[0,1]\n",
        "for i in range(0,len(A106)):\n",
        "      A106[i,1]=A106[i,1]- bias106    \n",
        "#print (A106)\n",
        "x106time= A106[:,1]/1000\n",
        "y106ac=[A106[:,2], A106[:,3], A106[:,4]] \n",
        "y106encoder= [A106[:,5], A106[:,6]]\n",
        "dy106ac_x=wavelet_denoising(y106ac[0])\n",
        "dy106ac_y=wavelet_denoising(y106ac[1])\n",
        "dy106ac_z=wavelet_denoising(y106ac[2])\n",
        "F106=alltop5points(dy106ac_x, dy89ac_y, dy106ac_z, x106time) \n",
        "F106=np.concatenate((F106,allenergy(dy106ac_x, dy106ac_y, dy106ac_z))) \n",
        "F106=np.concatenate((F106,correlation(dy106ac_x, dy106ac_y, dy106ac_z))) \n",
        "F106=np.append(F106,[jolt(dy106ac_x, '106')])\n",
        "F106=np.append(F106,[1]) #2\n",
        "F106=np.append(F106,[jolt(dy106ac_y, '106')])\n",
        "F106=np.append(F106,[1]) #2\n",
        "F106=np.append(F106,[x106time[len(x106time)-1]])\n",
        "y106encoder=np.array(y106encoder)\n",
        "newen=np.diff(y106encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F106=np.append(F106,[np.sum(newen)]) #add total number of turns\n",
        "F106=np.append(F106,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F106=np.append(F106,[len(newen[newen > 0])/x106time[len(x106time)-1]])\n",
        "F106=np.append(F106,[1,106]) \n",
        "F106=np.append(F106,[jolt(dy106ac_z, '106z')])\n",
        "F106=np.append(F106,[1]) #2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "984iFgtdaUiJ"
      },
      "outputs": [],
      "source": [
        "print('label 108')\n",
        "A108 = A[A[:, 7] == 108, :]  \n",
        "bias108=A108[0,1]\n",
        "for i in range(0,len(A108)):\n",
        "      A108[i,1]=A108[i,1]- bias108    \n",
        "#print (A108)\n",
        "x108time= A108[:,1]/1000\n",
        "y108ac=[A108[:,2], A108[:,3], A108[:,4]] \n",
        "y108encoder= [A108[:,5], A108[:,6]]\n",
        "dy108ac_x=wavelet_denoising(y108ac[0])\n",
        "dy108ac_y=wavelet_denoising(y108ac[1])\n",
        "dy108ac_z=wavelet_denoising(y108ac[2])\n",
        "F108=alltop5points(dy108ac_x, dy89ac_y, dy108ac_z, x108time) \n",
        "F108=np.concatenate((F108,allenergy(dy108ac_x, dy108ac_y, dy108ac_z)))\n",
        "F108=np.concatenate((F108,correlation(dy108ac_x, dy108ac_y, dy108ac_z))) \n",
        "F108=np.append(F108,[jolt(dy108ac_x, '108')])\n",
        "F108=np.append(F108,[2])\n",
        "F108=np.append(F108,[jolt(dy108ac_y, '108')])\n",
        "F108=np.append(F108,[4])\n",
        "F108=np.append(F108,[x108time[len(x108time)-1]])\n",
        "y108encoder=np.array(y108encoder)\n",
        "newen=np.diff(y108encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F108=np.append(F108,[np.sum(newen)]) #add total number of turns\n",
        "F108=np.append(F108,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F108=np.append(F108,[len(newen[newen > 0])/x108time[len(x108time)-1]])\n",
        "F108=np.append(F108,[0,108]) #label NA\n",
        "F108=np.append(F108,[jolt(dy108ac_z, '108z')])\n",
        "F108=np.append(F108,[4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUEfj_UaaZik"
      },
      "outputs": [],
      "source": [
        "print('label 112')\n",
        "A112 = A[A[:, 7] == 112, :]  \n",
        "bias112=A112[0,1]\n",
        "for i in range(0,len(A112)):\n",
        "      A112[i,1]=A112[i,1]- bias112    \n",
        "#print (A112)\n",
        "x112time= A112[:,1]/1000\n",
        "y112ac=[A112[:,2], A112[:,3], A112[:,4]] \n",
        "y112encoder= [A112[:,5], A112[:,6]] \n",
        "dy112ac_x=wavelet_denoising(y112ac[0])\n",
        "dy112ac_y=wavelet_denoising(y112ac[1])\n",
        "dy112ac_z=wavelet_denoising(y112ac[2])\n",
        "F112=alltop5points(dy112ac_x, dy89ac_y, dy112ac_z, x112time) \n",
        "F112=np.concatenate((F112,allenergy(dy112ac_x, dy112ac_y, dy112ac_z))) \n",
        "F112=np.concatenate((F112,correlation(dy112ac_x, dy112ac_y, dy112ac_z))) \n",
        "F112=np.append(F112,[jolt(dy112ac_x, '112')])\n",
        "F112=np.append(F112,[2]) #1\n",
        "F112=np.append(F112,[jolt(dy112ac_y, '112')])\n",
        "F112=np.append(F112,[2]) #3\n",
        "F112=np.append(F112,[x112time[len(x112time)-1]])\n",
        "y112encoder=np.array(y112encoder)\n",
        "newen=np.diff(y112encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F112=np.append(F112,[np.sum(newen)]) #add total number of turns\n",
        "F112=np.append(F112,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F112=np.append(F112,[len(newen[newen > 0])/x112time[len(x112time)-1]])\n",
        "F112=np.append(F112,[1,112])\n",
        "F112=np.append(F112,[jolt(dy112ac_z, '112z')])\n",
        "F112=np.append(F112,[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIAOwAfOad3J"
      },
      "outputs": [],
      "source": [
        "print('label 118')\n",
        "A118 = A[A[:, 7] == 118, :]  \n",
        "bias118=A118[0,1]\n",
        "for i in range(0,len(A118)):\n",
        "      A118[i,1]=A118[i,1]- bias118    \n",
        "#print (A118)\n",
        "x118time= A118[:,1]/1000\n",
        "y118ac=[A118[:,2], A118[:,3], A118[:,4]] \n",
        "y118encoder= [A118[:,5], A118[:,6]] \n",
        "dy118ac_x=wavelet_denoising(y118ac[0])\n",
        "dy118ac_y=wavelet_denoising(y118ac[1])\n",
        "dy118ac_z=wavelet_denoising(y118ac[2])\n",
        "F118=alltop5points(dy118ac_x, dy89ac_y, dy118ac_z, x118time) \n",
        "F118=np.concatenate((F118,allenergy(dy118ac_x, dy118ac_y, dy118ac_z))) \n",
        "F118=np.concatenate((F118,correlation(dy118ac_x, dy118ac_y, dy118ac_z))) \n",
        "F118=np.append(F118,[jolt(dy118ac_x, '118')])\n",
        "F118=np.append(F118,[3])\n",
        "F118=np.append(F118,[jolt(dy118ac_y, '118')])\n",
        "F118=np.append(F118,[4]) #5\n",
        "F118=np.append(F118,[x118time[len(x118time)-1]])\n",
        "y118encoder=np.array(y118encoder)\n",
        "newen=np.diff(y118encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F118=np.append(F118,[np.sum(newen)]) #add total number of turns\n",
        "F118=np.append(F118,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F118=np.append(F118,[len(newen[newen > 0])/x118time[len(x118time)-1]])\n",
        "F118=np.append(F118,[1,118]) \n",
        "F118=np.append(F118,[jolt(dy118ac_z, '118z')])\n",
        "F118=np.append(F118,[4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDI73ma1agrp"
      },
      "outputs": [],
      "source": [
        "print('label 120')\n",
        "A120 = A[A[:, 7] == 120, :] \n",
        "bias120=A120[0,1]\n",
        "for i in range(0,len(A120)):\n",
        "      A120[i,1]=A120[i,1]- bias120    \n",
        "#print (A120)\n",
        "x120time= A120[:,1]/1000\n",
        "y120ac=[A120[:,2], A120[:,3], A120[:,4]] \n",
        "y120encoder= [A120[:,5], A120[:,6]]\n",
        "dy120ac_x=wavelet_denoising(y120ac[0])\n",
        "dy120ac_y=wavelet_denoising(y120ac[1])\n",
        "dy120ac_z=wavelet_denoising(y120ac[2])\n",
        "F120=alltop5points(dy120ac_x, dy89ac_y, dy120ac_z, x120time) \n",
        "F120=np.concatenate((F120,allenergy(dy120ac_x, dy120ac_y, dy120ac_z))) \n",
        "F120=np.concatenate((F120,correlation(dy120ac_x, dy120ac_y, dy120ac_z)))\n",
        "F120=np.append(F120,[jolt(dy120ac_x, '120')])\n",
        "F120=np.append(F120,[6])\n",
        "F120=np.append(F120,[jolt(dy120ac_y, '120')])\n",
        "F120=np.append(F120,[6])\n",
        "F120=np.append(F120,[x120time[len(x120time)-1]])\n",
        "y120encoder=np.array(y120encoder)\n",
        "newen=np.diff(y120encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F120=np.append(F120,[np.sum(newen)]) #add total number of turns\n",
        "F120=np.append(F120,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F120=np.append(F120,[len(newen[newen > 0])/x120time[len(x120time)-1]])\n",
        "F120=np.append(F120,[0,120]) #label NA\n",
        "F120=np.append(F120,[jolt(dy120ac_z, '120z')])\n",
        "F120=np.append(F120,[6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc_jeK4-ahKN"
      },
      "outputs": [],
      "source": [
        "print('label 121')\n",
        "A121 = A[A[:, 7] == 121, :] \n",
        "bias121=A121[0,1]\n",
        "for i in range(0,len(A121)):\n",
        "      A121[i,1]=A121[i,1]- bias121   \n",
        "#print (A121)\n",
        "x121time= A121[:,1]/1000\n",
        "y121ac=[A121[:,2], A121[:,3], A121[:,4]] \n",
        "y121encoder= [A121[:,5], A121[:,6]]\n",
        "dy121ac_x=wavelet_denoising(y121ac[0])\n",
        "dy121ac_y=wavelet_denoising(y121ac[1])\n",
        "dy121ac_z=wavelet_denoising(y121ac[2])\n",
        "F121=alltop5points(dy121ac_x, dy89ac_y, dy121ac_z, x121time) \n",
        "F121=np.concatenate((F121,allenergy(dy121ac_x, dy121ac_y, dy121ac_z))) \n",
        "F121=np.concatenate((F121,correlation(dy121ac_x, dy121ac_y, dy121ac_z))) \n",
        "F121=np.append(F121,[jolt(dy121ac_x, '121')])\n",
        "F121=np.append(F121,[3])\n",
        "F121=np.append(F121,[jolt(dy121ac_y, '121')])\n",
        "F121=np.append(F121,[5])\n",
        "F121=np.append(F121,[x121time[len(x121time)-1]])\n",
        "y121encoder=np.array(y121encoder)\n",
        "newen=np.diff(y121encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F121=np.append(F121,[np.sum(newen)]) #add total number of turns\n",
        "F121=np.append(F121,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F121=np.append(F121,[len(newen[newen > 0])/x121time[len(x121time)-1]])\n",
        "F121=np.append(F121,[0,121]) #label NA\n",
        "F121=np.append(F121,[jolt(dy121ac_z, '121')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq-WPqyBajXx"
      },
      "outputs": [],
      "source": [
        "print('label 124')\n",
        "A124 = A[A[:, 7] == 124, :]  \n",
        "bias124=A124[0,1]\n",
        "for i in range(0,len(A124)):\n",
        "      A124[i,1]=A124[i,1]- bias124   \n",
        "#print (A124)\n",
        "x124time= A124[:,1]/1000\n",
        "y124ac=[A124[:,2], A124[:,3], A124[:,4]] \n",
        "y124encoder= [A124[:,5], A124[:,6]]\n",
        "dy124ac_x=wavelet_denoising(y124ac[0])\n",
        "dy124ac_y=wavelet_denoising(y124ac[1])\n",
        "dy124ac_z=wavelet_denoising(y124ac[2])\n",
        "F124=alltop5points(dy124ac_x, dy89ac_y, dy124ac_z, x124time) \n",
        "F124=np.concatenate((F124,allenergy(dy124ac_x, dy124ac_y, dy124ac_z))) \n",
        "F124=np.concatenate((F124,correlation(dy124ac_x, dy124ac_y, dy124ac_z))) \n",
        "F124=np.append(F124,[jolt(dy124ac_x, '124')])\n",
        "F124=np.append(F124,[4]) #3\n",
        "F124=np.append(F124,[jolt(dy124ac_y, '124')])\n",
        "F124=np.append(F124,[4]) #5\n",
        "F124=np.append(F124,[x124time[len(x124time)-1]])\n",
        "y124encoder=np.array(y124encoder)\n",
        "newen=np.diff(y124encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F124=np.append(F124,[np.sum(newen)]) #add total number of turns\n",
        "F124=np.append(F124,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F124=np.append(F124,[len(newen[newen > 0])/x124time[len(x124time)-1]])\n",
        "F124=np.append(F124,[0,124]) #label NA\n",
        "F124=np.append(F124,[jolt(dy124ac_z, '124')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF4OULl_alsi"
      },
      "outputs": [],
      "source": [
        "print('label 201')\n",
        "A201 = pd.read_csv(r'C:\\PythonCode\\A_amirali.csv')   \n",
        "#print (A201)\n",
        "A201=np.array(A201)\n",
        "A201=np.delete(A201, [1394], 0)\n",
        "A201 = np.vstack(A201[:, :]).astype(np.float)\n",
        "#print (A201)\n",
        "x201time= A201[:,0]\n",
        "y201ac=[A201[:,1], A201[:,2], A201[:,3]] #ac_x, ac_y, ac_z\n",
        "y201encoder= [A201[:,4],A201[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x201time, y201ac[0],89 ,0) #see the signal before denoising\n",
        "dy201ac_x=wavelet_denoising(y201ac[0])\n",
        "dy201ac_y=wavelet_denoising(y201ac[1])\n",
        "dy201ac_z=wavelet_denoising(y201ac[2])\n",
        "#plot1ac(x201time, y201ac[0], 201, 0)\n",
        "#plot1ac(x201time, dy201ac_x, 201, 1)\n",
        "F201=alltop5points(dy201ac_x, dy201ac_y, dy201ac_z, x201time) #feature vector=FV\n",
        "F201=np.concatenate((F201,allenergy(dy201ac_x, dy201ac_y, dy201ac_z))) #add energy to FV\n",
        "F201=np.concatenate((F201,correlation(dy201ac_x, dy201ac_y, dy201ac_z))) #add correlation coefficients to FV\n",
        "F201=np.append(F201,[jolt(dy201ac_x, '201')])#add jolt to FV\n",
        "F201=np.append(F201,[3])\n",
        "F201=np.append(F201,[jolt(dy201ac_y, '201')])#add jolt to FV\n",
        "F201=np.append(F201,[2]) #3\n",
        "F201=np.append(F201,[x201time[len(x201time)-1]])\n",
        "y201encoder=np.array(y201encoder)\n",
        "newen=np.diff(y201encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F201=np.append(F201,[np.sum(newen)]) #add total number of turns\n",
        "F201=np.append(F201,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F201=np.append(F201,[len(newen[newen > 0])/x201time[len(x201time)-1]])\n",
        "F201=np.append(F201,[1,201]) #label autistic\n",
        "F201=np.append(F201,[jolt(dy201ac_z, '201')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXRWrUrvaojx"
      },
      "outputs": [],
      "source": [
        "print('label 202')\n",
        "A202 = pd.read_csv(r'C:\\PythonCode\\A_artin-1.csv')   \n",
        "A202=np.array(A202)\n",
        "A202=np.delete(A202, [3622], 0)\n",
        "A202 = np.vstack(A202[:, :]).astype(np.float)\n",
        "x202time= A202[:,0]\n",
        "y202ac=[A202[:,1], A202[:,2], A202[:,3]] #ac_x, ac_y, ac_z\n",
        "y202encoder= [A202[:,4],A202[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x202time, y202ac[0],89 ,0) #see the signal before denoising\n",
        "dy202ac_x=wavelet_denoising(y202ac[0])\n",
        "dy202ac_y=wavelet_denoising(y202ac[1])\n",
        "dy202ac_z=wavelet_denoising(y202ac[2])\n",
        "#plot1ac(x202time, y202ac[0], 202, 0)\n",
        "#plot1ac(x202time, dy202ac_x, 202, 1)\n",
        "F202=alltop5points(dy202ac_x, dy202ac_y, dy202ac_z, x202time) #feature vector=FV\n",
        "F202=np.concatenate((F202,allenergy(dy202ac_x, dy202ac_y, dy202ac_z))) #add energy to FV\n",
        "F202=np.concatenate((F202,correlation(dy202ac_x, dy202ac_y, dy202ac_z))) #add correlation coefficients to FV\n",
        "F202=np.append(F202,[jolt(dy202ac_x, '202')])#add jolt to FV\n",
        "F202=np.append(F202,[6])\n",
        "F202=np.append(F202,[jolt(dy202ac_y, '202')])#add jolt to FV\n",
        "F202=np.append(F202,[10])\n",
        "F202=np.append(F202,[x202time[len(x202time)-1]])\n",
        "y202encoder=np.array(y202encoder)\n",
        "newen=np.diff(y202encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F202=np.append(F202,[np.sum(newen)]) #add total number of turns\n",
        "F202=np.append(F202,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F202=np.append(F202,[len(newen[newen > 0])/x202time[len(x202time)-1]])\n",
        "F202=np.append(F202,[1,202]) #label autistic\n",
        "F202=np.append(F202,[jolt(dy202ac_z, '202')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOm-czcuaqz6"
      },
      "outputs": [],
      "source": [
        "print('label 203')\n",
        "A203 = pd.read_csv(r'C:\\PythonCode\\A_meshkat  alekazem.csv')   \n",
        "A203=np.array(A203)\n",
        "A203=np.delete(A203, [2179], 0)\n",
        "A203 = np.vstack(A203[:, :]).astype(np.float)\n",
        "x203time= A203[:,0]\n",
        "y203ac=[A203[:,1], A203[:,2], A203[:,3]] #ac_x, ac_y, ac_z\n",
        "y203encoder= [A203[:,4],A203[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x203time, y203ac[0],89 ,0) #see the signal before denoising\n",
        "dy203ac_x=wavelet_denoising(y203ac[0])\n",
        "dy203ac_y=wavelet_denoising(y203ac[1])\n",
        "dy203ac_z=wavelet_denoising(y203ac[2])\n",
        "#plot1ac(x203time, y203ac[0], 203, 0)\n",
        "#plot1ac(x203time, dy203ac_x, 203, 1)\n",
        "F203=alltop5points(dy203ac_x, dy203ac_y, dy203ac_z, x203time) #feature vector=FV\n",
        "F203=np.concatenate((F203,allenergy(dy203ac_x, dy203ac_y, dy203ac_z))) #add energy to FV\n",
        "F203=np.concatenate((F203,correlation(dy203ac_x, dy203ac_y, dy203ac_z))) #add correlation coefficients to FV\n",
        "F203=np.append(F203,[jolt(dy203ac_x, '203')])#add jolt to FV\n",
        "F203=np.append(F203,[3]) #2\n",
        "F203=np.append(F203,[jolt(dy203ac_y, '203')])#add jolt to FV\n",
        "F203=np.append(F203,[1])\n",
        "F203=np.append(F203,[x203time[len(x203time)-1]])\n",
        "y203encoder=np.array(y203encoder)\n",
        "newen=np.diff(y203encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F203=np.append(F203,[np.sum(newen)]) #add total number of turns\n",
        "F203=np.append(F203,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F203=np.append(F203,[len(newen[newen > 0])/x203time[len(x203time)-1]])\n",
        "F203=np.append(F203,[1,203]) #label autistic\n",
        "F203=np.append(F203,[jolt(dy203ac_z, '203')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG3-PXNoat2z"
      },
      "outputs": [],
      "source": [
        "print('label 204')\n",
        "A204 = pd.read_csv(r'C:\\PythonCode\\A_keyvan maleki.csv')   \n",
        "A204=np.array(A204)\n",
        "A204=np.delete(A204, [4525], 0)\n",
        "A204 = np.vstack(A204[:, :]).astype(np.float)\n",
        "x204time= A204[:,0]\n",
        "y204ac=[A204[:,1], A204[:,2], A204[:,3]] #ac_x, ac_y, ac_z\n",
        "y204encoder= [A204[:,4],A204[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x204time, y204ac[0],89 ,0) #see the signal before denoising\n",
        "dy204ac_x=wavelet_denoising(y204ac[0])\n",
        "dy204ac_y=wavelet_denoising(y204ac[1])\n",
        "dy204ac_z=wavelet_denoising(y204ac[2])\n",
        "#plot1ac(x204time, y204ac[0], 204, 0)\n",
        "#plot1ac(x204time, dy204ac_x, 204, 1)\n",
        "F204=alltop5points(dy204ac_x, dy204ac_y, dy204ac_z, x204time) #feature vector=FV\n",
        "F204=np.concatenate((F204,allenergy(dy204ac_x, dy204ac_y, dy204ac_z))) #add energy to FV\n",
        "F204=np.concatenate((F204,correlation(dy204ac_x, dy204ac_y, dy204ac_z))) #add correlation coefficients to FV\n",
        "F204=np.append(F204,[jolt(dy204ac_x, '204')])#add jolt to FV\n",
        "F204=np.append(F204,[3])\n",
        "F204=np.append(F204,[jolt(dy204ac_y, '204')])#add jolt to FV\n",
        "F204=np.append(F204,[5])\n",
        "F204=np.append(F204,[x204time[len(x204time)-1]])\n",
        "y204encoder=np.array(y204encoder)\n",
        "newen=np.diff(y204encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F204=np.append(F204,[np.sum(newen)]) #add total number of turns\n",
        "F204=np.append(F204,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F204=np.append(F204,[len(newen[newen > 0])/x204time[len(x204time)-1]])\n",
        "F204=np.append(F204,[1,204]) #label autistic\n",
        "F204=np.append(F204,[jolt(dy204ac_z, '204')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g597fkQawbA"
      },
      "outputs": [],
      "source": [
        "print('label 205')\n",
        "A205 = pd.read_csv(r'C:\\PythonCode\\A_nika ziaee.csv')   \n",
        "A205=np.array(A205)\n",
        "A205=np.delete(A205, [5347], 0)\n",
        "A205 = np.vstack(A205[:, :]).astype(np.float)\n",
        "x205time= A205[:,0]\n",
        "y205ac=[A205[:,1], A205[:,2], A205[:,3]] #ac_x, ac_y, ac_z\n",
        "y205encoder= [A205[:,4],A205[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x205time, y205ac[0],89 ,0) #see the signal before denoising\n",
        "dy205ac_x=wavelet_denoising(y205ac[0])\n",
        "dy205ac_y=wavelet_denoising(y205ac[1])\n",
        "dy205ac_z=wavelet_denoising(y205ac[2])\n",
        "#plot1ac(x205time, y205ac[0], 205, 0)\n",
        "#plot1ac(x205time, dy205ac_x, 205, 1)\n",
        "F205=alltop5points(dy205ac_x, dy205ac_y, dy205ac_z, x205time) #feature vector=FV\n",
        "F205=np.concatenate((F205,allenergy(dy205ac_x, dy205ac_y, dy205ac_z))) #add energy to FV\n",
        "F205=np.concatenate((F205,correlation(dy205ac_x, dy205ac_y, dy205ac_z))) #add correlation coefficients to FV\n",
        "F205=np.append(F205,[jolt(dy205ac_x, '205')])#add jolt to FV\n",
        "F205=np.append(F205,[5])\n",
        "F205=np.append(F205,[jolt(dy205ac_y, '205')])#add jolt to FV\n",
        "F205=np.append(F205,[7])\n",
        "F205=np.append(F205,[x205time[len(x205time)-1]])\n",
        "y205encoder=np.array(y205encoder)\n",
        "newen=np.diff(y205encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F205=np.append(F205,[np.sum(newen)]) #add total number of turns\n",
        "F205=np.append(F205,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F205=np.append(F205,[len(newen[newen > 0])/x205time[len(x205time)-1]])\n",
        "F205=np.append(F205,[1,205]) #label autistic\n",
        "F205=np.append(F205,[jolt(dy205ac_z, '205')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOk--AZiayWw"
      },
      "outputs": [],
      "source": [
        "print('label 206')\n",
        "A206 = pd.read_csv(r'C:\\PythonCode\\A_arad.csv')   \n",
        "A206=np.array(A206)\n",
        "A206=np.delete(A206, [408], 0)\n",
        "A206 = np.vstack(A206[:, :]).astype(np.float)\n",
        "x206time= A206[:,0]\n",
        "y206ac=[A206[:,1], A206[:,2], A206[:,3]] #ac_x, ac_y, ac_z\n",
        "y206encoder= [A206[:,4],A206[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x206time, y206ac[0],89 ,0) #see the signal before denoising\n",
        "dy206ac_x=wavelet_denoising(y206ac[0])\n",
        "dy206ac_y=wavelet_denoising(y206ac[1])\n",
        "dy206ac_z=wavelet_denoising(y206ac[2])\n",
        "#plot1ac(x206time, y206ac[0], 206, 0)\n",
        "#plot1ac(x206time, dy206ac_x, 206, 1)\n",
        "F206=alltop5points(dy206ac_x, dy206ac_y, dy206ac_z, x206time) #feature vector=FV\n",
        "F206=np.concatenate((F206,allenergy(dy206ac_x, dy206ac_y, dy206ac_z))) #add energy to FV\n",
        "F206=np.concatenate((F206,correlation(dy206ac_x, dy206ac_y, dy206ac_z))) #add correlation coefficients to FV\n",
        "F206=np.append(F206,[jolt(dy206ac_x, '206')])#add jolt to FV\n",
        "F206=np.append(F206,[1])\n",
        "F206=np.append(F206,[jolt(dy206ac_y, '206')])#add jolt to FV\n",
        "F206=np.append(F206,[2])\n",
        "F206=np.append(F206,[x206time[len(x206time)-1]])\n",
        "y206encoder=np.array(y206encoder)\n",
        "newen=np.diff(y206encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F206=np.append(F206,[np.sum(newen)]) #add total number of turns\n",
        "F206=np.append(F206,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F206=np.append(F206,[len(newen[newen > 0])/x206time[len(x206time)-1]])\n",
        "F206=np.append(F206,[1,206]) #label autistic\n",
        "F206=np.append(F206,[jolt(dy206ac_z, '206')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0uJKORua0yS"
      },
      "outputs": [],
      "source": [
        "print('label 207')\n",
        "A207 = pd.read_csv(r'C:\\PythonCode\\A_abolfazl.csv')   \n",
        "A207=np.array(A207)\n",
        "A207 = np.vstack(A207[:, :]).astype(np.float)\n",
        "x207time= A207[:,0]\n",
        "y207ac=[A207[:,1], A207[:,2], A207[:,3]] #ac_x, ac_y, ac_z\n",
        "y207encoder= [A207[:,4],A207[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x207time, y207ac[0],89 ,0) #see the signal before denoising\n",
        "dy207ac_x=wavelet_denoising(y207ac[0])\n",
        "dy207ac_y=wavelet_denoising(y207ac[1])\n",
        "dy207ac_z=wavelet_denoising(y207ac[2])\n",
        "#plot1ac(x207time, y207ac[0], 207, 0)\n",
        "#plot1ac(x207time, dy207ac_x, 207, 1)\n",
        "F207=alltop5points(dy207ac_x, dy207ac_y, dy207ac_z, x207time) #feature vector=FV\n",
        "F207=np.concatenate((F207,allenergy(dy207ac_x, dy207ac_y, dy207ac_z))) #add energy to FV\n",
        "F207=np.concatenate((F207,correlation(dy207ac_x, dy207ac_y, dy207ac_z))) #add correlation coefficients to FV\n",
        "F207=np.append(F207,[jolt(dy207ac_x, '207')])#add jolt to FV\n",
        "F207=np.append(F207,[2])\n",
        "F207=np.append(F207,[jolt(dy207ac_y, '207')])#add jolt to FV\n",
        "F207=np.append(F207,[2]) #2\n",
        "F207=np.append(F207,[x207time[len(x207time)-1]])\n",
        "y207encoder=np.array(y207encoder)\n",
        "newen=np.diff(y207encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F207=np.append(F207,[np.sum(newen)]) #add total number of turns\n",
        "F207=np.append(F207,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F207=np.append(F207,[len(newen[newen > 0])/x207time[len(x207time)-1]])\n",
        "F207=np.append(F207,[1,207]) #label autistic\n",
        "F207=np.append(F207,[jolt(dy207ac_z, '207')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URQ-Oen0a3E1"
      },
      "outputs": [],
      "source": [
        "print('label 208')\n",
        "A208 = pd.read_csv(r'C:\\PythonCode\\A_adrian abdolahzadeh.csv')   \n",
        "A208=np.array(A208)\n",
        "A208 = np.vstack(A208[:, :]).astype(np.float)\n",
        "x208time= A208[:,0]\n",
        "y208ac=[A208[:,1], A208[:,2], A208[:,3]] #ac_x, ac_y, ac_z\n",
        "y208encoder= [A208[:,4],A208[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x208time, y208ac[0],89 ,0) #see the signal before denoising\n",
        "dy208ac_x=wavelet_denoising(y208ac[0])\n",
        "dy208ac_y=wavelet_denoising(y208ac[1])\n",
        "dy208ac_z=wavelet_denoising(y208ac[2])\n",
        "#plot1ac(x208time, y208ac[0], 208, 0)\n",
        "#plot1ac(x208time, dy208ac_x, 208, 1)\n",
        "F208=alltop5points(dy208ac_x, dy208ac_y, dy208ac_z, x208time) #feature vector=FV\n",
        "F208=np.concatenate((F208,allenergy(dy208ac_x, dy208ac_y, dy208ac_z))) #add energy to FV\n",
        "F208=np.concatenate((F208,correlation(dy208ac_x, dy208ac_y, dy208ac_z))) #add correlation coefficients to FV\n",
        "F208=np.append(F208,[jolt(dy208ac_x, '208')])#add jolt to FV\n",
        "F208=np.append(F208,[4]) #5\n",
        "F208=np.append(F208,[jolt(dy208ac_y, '208')])#add jolt to FV\n",
        "F208=np.append(F208,[3])\n",
        "F208=np.append(F208,[x208time[len(x208time)-1]])\n",
        "y208encoder=np.array(y208encoder)\n",
        "newen=np.diff(y208encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F208=np.append(F208,[np.sum(newen)]) #add total number of turns\n",
        "F208=np.append(F208,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F208=np.append(F208,[len(newen[newen > 0])/x208time[len(x208time)-1]])\n",
        "F208=np.append(F208,[1,208]) #label autistic\n",
        "F208=np.append(F208,[jolt(dy208ac_z, '208')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X45rD7La5cc"
      },
      "outputs": [],
      "source": [
        "print('label 209')\n",
        "A209 = pd.read_csv(r'C:\\PythonCode\\A_arian hashemi.csv')   \n",
        "A209=np.array(A209)\n",
        "A209 = np.vstack(A209[:, :]).astype(np.float)\n",
        "x209time= A209[:,0]\n",
        "y209ac=[A209[:,1], A209[:,2], A209[:,3]] #ac_x, ac_y, ac_z\n",
        "y209encoder= [A209[:,4],A209[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x209time, y209ac[0],89 ,0) #see the signal before denoising\n",
        "dy209ac_x=wavelet_denoising(y209ac[0])\n",
        "dy209ac_y=wavelet_denoising(y209ac[1])\n",
        "dy209ac_z=wavelet_denoising(y209ac[2])\n",
        "#plot1ac(x209time, y209ac[0], 209, 0)\n",
        "#plot1ac(x209time, dy209ac_x, 209, 1)\n",
        "F209=alltop5points(dy209ac_x, dy209ac_y, dy209ac_z, x209time) #feature vector=FV\n",
        "F209=np.concatenate((F209,allenergy(dy209ac_x, dy209ac_y, dy209ac_z))) #add energy to FV\n",
        "F209=np.concatenate((F209,correlation(dy209ac_x, dy209ac_y, dy209ac_z))) #add correlation coefficients to FV\n",
        "F209=np.append(F209,[jolt(dy209ac_x, '209')])#add jolt to FV\n",
        "F209=np.append(F209,[4]) #5\n",
        "F209=np.append(F209,[jolt(dy209ac_y, '209')])#add jolt to FV\n",
        "F209=np.append(F209,[4]) #4\n",
        "F209=np.append(F209,[x209time[len(x209time)-1]])\n",
        "y209encoder=np.array(y209encoder)\n",
        "newen=np.diff(y209encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F209=np.append(F209,[np.sum(newen)]) #add total number of turns\n",
        "F209=np.append(F209,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F209=np.append(F209,[len(newen[newen > 0])/x209time[len(x209time)-1]])\n",
        "F209=np.append(F209,[1,209]) #label autistic\n",
        "F209=np.append(F209,[jolt(dy209ac_z, '209')])#add jolt to FV\n",
        "F209=np.append(F209,[4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC0nnTz1a8wz"
      },
      "outputs": [],
      "source": [
        "print('label 210')\n",
        "A210 = pd.read_csv(r'C:\\PythonCode\\A_ayleen bidar.csv')   \n",
        "A210=np.array(A210)\n",
        "A210=np.delete(A205, [3439], 0)\n",
        "A210 = np.vstack(A210[:, :]).astype(np.float)\n",
        "x210time= A210[:,0]\n",
        "y210ac=[A210[:,1], A210[:,2], A210[:,3]] #ac_x, ac_y, ac_z\n",
        "y210encoder= [A210[:,4],A210[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x210time, y210ac[0],89 ,0) #see the signal before denoising\n",
        "dy210ac_x=wavelet_denoising(y210ac[0])\n",
        "dy210ac_y=wavelet_denoising(y210ac[1])\n",
        "dy210ac_z=wavelet_denoising(y210ac[2])\n",
        "#plot1ac(x210time, y210ac[0], 210, 0)\n",
        "#plot1ac(x210time, dy210ac_x, 210, 1)\n",
        "F210=alltop5points(dy210ac_x, dy210ac_y, dy210ac_z, x210time) #feature vector=FV\n",
        "F210=np.concatenate((F210,allenergy(dy210ac_x, dy210ac_y, dy210ac_z))) #add energy to FV\n",
        "F210=np.concatenate((F210,correlation(dy210ac_x, dy210ac_y, dy210ac_z))) #add correlation coefficients to FV\n",
        "F210=np.append(F210,[jolt(dy210ac_x, '210')])#add jolt to FV\n",
        "F210=np.append(F210,[6])\n",
        "F210=np.append(F210,[jolt(dy210ac_y, '210')])#add jolt to FV\n",
        "F210=np.append(F210,[7])\n",
        "F210=np.append(F210,[x210time[len(x210time)-1]])\n",
        "y210encoder=np.array(y210encoder)\n",
        "newen=np.diff(y210encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F210=np.append(F210,[np.sum(newen)]) #add total number of turns\n",
        "F210=np.append(F210,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F210=np.append(F210,[len(newen[newen > 0])/x210time[len(x210time)-1]])\n",
        "F210=np.append(F210,[1,210]) #label autistic\n",
        "F210=np.append(F210,[jolt(dy210ac_z, '210')])#add jolt to FV\n",
        "F210=np.append(F210,[7])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV4krR3oa-vY"
      },
      "outputs": [],
      "source": [
        "print('label 211')\n",
        "A211 = pd.read_csv(r'C:\\PythonCode\\A_ayleen kamani.csv')   \n",
        "A211=np.array(A211)\n",
        "A211 = np.vstack(A211[:, :]).astype(np.float)\n",
        "x211time= A211[:,0]\n",
        "y211ac=[A211[:,1], A211[:,2], A211[:,3]] #ac_x, ac_y, ac_z\n",
        "y211encoder= [A211[:,4],A211[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x211time, y211ac[0],89 ,0) #see the signal before denoising\n",
        "dy211ac_x=wavelet_denoising(y211ac[0])\n",
        "dy211ac_y=wavelet_denoising(y211ac[1])\n",
        "dy211ac_z=wavelet_denoising(y211ac[2])\n",
        "#plot1ac(x211time, y211ac[0], 211, 0)\n",
        "#plot1ac(x211time, dy211ac_x, 211, 1)\n",
        "F211=alltop5points(dy211ac_x, dy211ac_y, dy211ac_z, x211time) #feature vector=FV\n",
        "F211=np.concatenate((F211,allenergy(dy211ac_x, dy211ac_y, dy211ac_z))) #add energy to FV\n",
        "F211=np.concatenate((F211,correlation(dy211ac_x, dy211ac_y, dy211ac_z))) #add correlation coefficients to FV\n",
        "F211=np.append(F211,[jolt(dy211ac_x, '211')])#add jolt to FV\n",
        "F211=np.append(F211,[6]) #5\n",
        "F211=np.append(F211,[jolt(dy211ac_y, '211')])#add jolt to FV\n",
        "F211=np.append(F211,[5])\n",
        "F211=np.append(F211,[x211time[len(x211time)-1]])\n",
        "y211encoder=np.array(y211encoder)\n",
        "newen=np.diff(y211encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F211=np.append(F211,[np.sum(newen)]) #add total number of turns\n",
        "F211=np.append(F211,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F211=np.append(F211,[len(newen[newen > 0])/x211time[len(x211time)-1]])\n",
        "F211=np.append(F211,[1,211]) #label autistic\n",
        "F211=np.append(F211,[jolt(dy211ac_z, '211')])#add jolt to FV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ3LfVwIbBH3"
      },
      "outputs": [],
      "source": [
        "print('label 212')\n",
        "A212 = pd.read_csv(r'C:\\PythonCode\\A_golsa yadegari.csv')   \n",
        "A212=np.array(A212)\n",
        "A212 = np.vstack(A212[:, :]).astype(np.float)\n",
        "x212time= A212[:,0]\n",
        "y212ac=[A212[:,1], A212[:,2], A212[:,3]] #ac_x, ac_y, ac_z\n",
        "y212encoder= [A212[:,4],A212[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x212time, y212ac[0],89 ,0) #see the signal before denoising\n",
        "dy212ac_x=wavelet_denoising(y212ac[0])\n",
        "dy212ac_y=wavelet_denoising(y212ac[1])\n",
        "dy212ac_z=wavelet_denoising(y212ac[2])\n",
        "#plot1ac(x212time, y212ac[0], 212, 0)\n",
        "#plot1ac(x212time, dy212ac_x, 212, 1)\n",
        "F212=alltop5points(dy212ac_x, dy212ac_y, dy212ac_z, x212time) #feature vector=FV\n",
        "F212=np.concatenate((F212,allenergy(dy212ac_x, dy212ac_y, dy212ac_z))) #add energy to FV\n",
        "F212=np.concatenate((F212,correlation(dy212ac_x, dy212ac_y, dy212ac_z))) #add correlation coefficients to FV\n",
        "F212=np.append(F212,[jolt(dy212ac_x, '212')])#add jolt to FV\n",
        "F212=np.append(F212,[6]) #5\n",
        "F212=np.append(F212,[jolt(dy212ac_y, '212')])#add jolt to FV\n",
        "F212=np.append(F212,[7]) #6\n",
        "F212=np.append(F212,[x212time[len(x212time)-1]])\n",
        "y212encoder=np.array(y212encoder)\n",
        "newen=np.diff(y212encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F212=np.append(F212,[np.sum(newen)]) #add total number of turns\n",
        "F212=np.append(F212,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F212=np.append(F212,[len(newen[newen > 0])/x212time[len(x212time)-1]])\n",
        "F212=np.append(F212,[1,212]) #label autistic\n",
        "F212=np.append(F212,[jolt(dy212ac_z, '212')])#add jolt to FV\n",
        "F212=np.append(F212,[7]) #6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c78pSTW3bJAg"
      },
      "outputs": [],
      "source": [
        "print('label 213')\n",
        "A213 = pd.read_csv(r'C:\\PythonCode\\A_kasra bahmani.csv')   \n",
        "A213=np.array(A213)\n",
        "A213 = np.vstack(A213[:, :]).astype(np.float)\n",
        "x213time= A213[:,0]\n",
        "y213ac=[A213[:,1], A213[:,2], A213[:,3]] #ac_x, ac_y, ac_z\n",
        "y213encoder= [A213[:,4],A213[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x213time, y213ac[0],89 ,0) #see the signal before denoising\n",
        "dy213ac_x=wavelet_denoising(y213ac[0])\n",
        "dy213ac_y=wavelet_denoising(y213ac[1])\n",
        "dy213ac_z=wavelet_denoising(y213ac[2])\n",
        "#plot1ac(x213time, y213ac[0], 213, 0)\n",
        "#plot1ac(x213time, dy213ac_x, 213, 1)\n",
        "F213=alltop5points(dy213ac_x, dy213ac_y, dy213ac_z, x213time) #feature vector=FV\n",
        "F213=np.concatenate((F213,allenergy(dy213ac_x, dy213ac_y, dy213ac_z))) #add energy to FV\n",
        "F213=np.concatenate((F213,correlation(dy213ac_x, dy213ac_y, dy213ac_z))) #add correlation coefficients to FV\n",
        "F213=np.append(F213,[jolt(dy213ac_x, '213')])#add jolt to FV\n",
        "F213=np.append(F213,[3]) #4\n",
        "F213=np.append(F213,[jolt(dy213ac_y, '213')])#add jolt to FV\n",
        "F213=np.append(F213,[4])\n",
        "F213=np.append(F213,[x213time[len(x213time)-1]])\n",
        "y213encoder=np.array(y213encoder)\n",
        "newen=np.diff(y213encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F213=np.append(F213,[np.sum(newen)]) #add total number of turns\n",
        "F213=np.append(F213,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F213=np.append(F213,[len(newen[newen > 0])/x213time[len(x213time)-1]])\n",
        "F213=np.append(F213,[1,213]) #label autistic\n",
        "F213=np.append(F213,[jolt(dy213ac_z, '213')])#add jolt to FV\n",
        "F213=np.append(F213,[4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX6k5m9ObK0w"
      },
      "outputs": [],
      "source": [
        "print('label 214')\n",
        "A214 = pd.read_csv(r'C:\\PythonCode\\A_mahdiar.csv')   \n",
        "A214=np.array(A214)\n",
        "A214 = np.vstack(A214[:, :]).astype(np.float)\n",
        "x214time= A214[:,0]\n",
        "y214ac=[A214[:,1], A214[:,2], A214[:,3]] #ac_x, ac_y, ac_z\n",
        "y214encoder= [A214[:,4],A214[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x214time, y214ac[0],89 ,0) #see the signal before denoising\n",
        "dy214ac_x=wavelet_denoising(y214ac[0])\n",
        "dy214ac_y=wavelet_denoising(y214ac[1])\n",
        "dy214ac_z=wavelet_denoising(y214ac[2])\n",
        "#plot1ac(x214time, y214ac[0], 214, 0)\n",
        "#plot1ac(x214time, dy214ac_x, 214, 1)\n",
        "F214=alltop5points(dy214ac_x, dy214ac_y, dy214ac_z, x214time) #feature vector=FV\n",
        "F214=np.concatenate((F214,allenergy(dy214ac_x, dy214ac_y, dy214ac_z))) #add energy to FV\n",
        "F214=np.concatenate((F214,correlation(dy214ac_x, dy214ac_y, dy214ac_z))) #add correlation coefficients to FV\n",
        "F214=np.append(F214,[jolt(dy214ac_x, '214')])#add jolt to FV\n",
        "F214=np.append(F214,[1]) #2\n",
        "F214=np.append(F214,[jolt(dy214ac_y, '214')])#add jolt to FV\n",
        "F214=np.append(F214,[3])\n",
        "F214=np.append(F214,[x214time[len(x214time)-1]])\n",
        "y214encoder=np.array(y214encoder)\n",
        "newen=np.diff(y214encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F214=np.append(F214,[np.sum(newen)]) #add total number of turns\n",
        "F214=np.append(F214,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F214=np.append(F214,[len(newen[newen > 0])/x214time[len(x214time)-1]])\n",
        "F214=np.append(F214,[1,214]) #label autistic\n",
        "F214=np.append(F214,[jolt(dy214ac_z, '214')])#add jolt to FV\n",
        "F214=np.append(F214,[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAwYKSzBbNth"
      },
      "outputs": [],
      "source": [
        "print('label 215')\n",
        "A215 = pd.read_csv(r'C:\\PythonCode\\A_matin moghtaderian.csv')   \n",
        "#print (A215)\n",
        "A215=np.array(A215)\n",
        "A215 = np.vstack(A215[:, :]).astype(np.float)\n",
        "#print (A215)\n",
        "x215time= A215[:,0]\n",
        "y215ac=[A215[:,1], A215[:,2], A215[:,3]] #ac_x, ac_y, ac_z\n",
        "y215encoder= [A215[:,4],A215[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x215time, y215ac[0],89 ,0) #see the signal before denoising\n",
        "dy215ac_x=wavelet_denoising(y215ac[0])\n",
        "dy215ac_y=wavelet_denoising(y215ac[1])\n",
        "dy215ac_z=wavelet_denoising(y215ac[2])\n",
        "#plot1ac(x215time, y215ac[0], 215, 0)\n",
        "#plot1ac(x215time, dy215ac_x, 215, 1)\n",
        "F215=alltop5points(dy215ac_x, dy215ac_y, dy215ac_z, x215time) #feature vector=FV\n",
        "F215=np.concatenate((F215,allenergy(dy215ac_x, dy215ac_y, dy215ac_z))) #add energy to FV\n",
        "F215=np.concatenate((F215,correlation(dy215ac_x, dy215ac_y, dy215ac_z))) #add correlation coefficients to FV\n",
        "F215=np.append(F215,[jolt(dy215ac_x, '215')])#add jolt to FV\n",
        "F215=np.append(F215,[3]) #4\n",
        "F215=np.append(F215,[jolt(dy215ac_y, '215')])#add jolt to FV\n",
        "F215=np.append(F215,[6])\n",
        "F215=np.append(F215,[x215time[len(x215time)-1]])\n",
        "y215encoder=np.array(y215encoder)\n",
        "newen=np.diff(y215encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F215=np.append(F215,[np.sum(newen)]) #add total number of turns\n",
        "F215=np.append(F215,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F215=np.append(F215,[len(newen[newen > 0])/x215time[len(x215time)-1]])\n",
        "F215=np.append(F215,[1,215]) #label autistic\n",
        "F215=np.append(F215,[jolt(dy215ac_z, '215')])#add jolt to FV\n",
        "F215=np.append(F215,[6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-77vYjwjbQIk"
      },
      "outputs": [],
      "source": [
        "print('label 216')\n",
        "A216 = pd.read_csv(r'C:\\PythonCode\\A_narjes dow.csv')   \n",
        "#print (A216)\n",
        "A216=np.array(A216)\n",
        "A216 = np.vstack(A216[:, :]).astype(np.float)\n",
        "#print (A216)\n",
        "x216time= A216[:,0]\n",
        "y216ac=[A216[:,1], A216[:,2], A216[:,3]] #ac_x, ac_y, ac_z\n",
        "y216encoder= [A216[:,4],A216[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x216time, y216ac[0],89 ,0) #see the signal before denoising\n",
        "dy216ac_x=wavelet_denoising(y216ac[0])\n",
        "dy216ac_y=wavelet_denoising(y216ac[1])\n",
        "dy216ac_z=wavelet_denoising(y216ac[2])\n",
        "#plot1ac(x216time, y216ac[0], 216, 0)\n",
        "#plot1ac(x216time, dy216ac_x, 216, 1)\n",
        "F216=alltop5points(dy216ac_x, dy216ac_y, dy216ac_z, x216time) #feature vector=FV\n",
        "F216=np.concatenate((F216,allenergy(dy216ac_x, dy216ac_y, dy216ac_z))) #add energy to FV\n",
        "F216=np.concatenate((F216,correlation(dy216ac_x, dy216ac_y, dy216ac_z))) #add correlation coefficients to FV\n",
        "F216=np.append(F216,[jolt(dy216ac_x, '216')])#add jolt to FV\n",
        "F216=np.append(F216,[2])\n",
        "F216=np.append(F216,[jolt(dy216ac_y, '216')])#add jolt to FV\n",
        "F216=np.append(F216,[2])\n",
        "F216=np.append(F216,[x216time[len(x216time)-1]])\n",
        "y216encoder=np.array(y216encoder)\n",
        "newen=np.diff(y216encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F216=np.append(F216,[np.sum(newen)]) #add total number of turns\n",
        "F216=np.append(F216,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F216=np.append(F216,[len(newen[newen > 0])/x216time[len(x216time)-1]])\n",
        "F216=np.append(F216,[1,216]) #label autistic\n",
        "F216=np.append(F216,[jolt(dy216ac_z, '216')])#add jolt to FV\n",
        "F216=np.append(F216,[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPVjNnoWbSIY"
      },
      "outputs": [],
      "source": [
        "#strange data\n",
        "print('label 217')\n",
        "A217 = pd.read_csv(r'C:\\PythonCode\\A_parsa shamsaee.csv')   \n",
        "A217=np.array(A217)\n",
        "A217=np.delete(A217, [2580], 0)\n",
        "A217 = np.vstack(A217[:, :]).astype(np.float)\n",
        "x217time= A217[:,0]\n",
        "y217ac=[A217[:,1], A217[:,2], A217[:,3]] #ac_x, ac_y, ac_z\n",
        "y217encoder= [A217[:,4],A217[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x217time, y217ac[0],89 ,0) #see the signal before denoising\n",
        "dy217ac_x=wavelet_denoising(y217ac[0])\n",
        "dy217ac_y=wavelet_denoising(y217ac[1])\n",
        "dy217ac_z=wavelet_denoising(y217ac[2])\n",
        "#plot1ac(x217time, y217ac[0], 217, 0)\n",
        "#plot1ac(x217time, dy217ac_x, 217, 1)\n",
        "F217=alltop5points(dy217ac_x, dy217ac_y, dy217ac_z, x217time) #feature vector=FV\n",
        "F217=np.concatenate((F217,allenergy(dy217ac_x, dy217ac_y, dy217ac_z))) #add energy to FV\n",
        "F217=np.concatenate((F217,correlation(dy217ac_x, dy217ac_y, dy217ac_z))) #add correlation coefficients to FV\n",
        "F217=np.append(F217,[jolt(dy217ac_x, '217')])#add jolt to FV\n",
        "F217=np.append(F217,[4]) #6\n",
        "F217=np.append(F217,[jolt(dy217ac_y, '217')])#add jolt to FV\n",
        "F217=np.append(F217,[7])\n",
        "F217=np.append(F217,[x217time[len(x217time)-1]])\n",
        "y217encoder=np.array(y217encoder)\n",
        "newen=np.diff(y217encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F217=np.append(F217,[np.sum(newen)]) #add total number of turns\n",
        "F217=np.append(F217,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F217=np.append(F217,[len(newen[newen > 0])/x217time[len(x217time)-1]])\n",
        "F217=np.append(F217,[1,217]) #label autistic\n",
        "F217=np.append(F217,[jolt(dy217ac_z, '217')])#add jolt to FV\n",
        "F217=np.append(F217,[7])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihPcprJVbce1"
      },
      "outputs": [],
      "source": [
        "print('label 218')\n",
        "A218 = pd.read_csv(r'C:\\PythonCode\\A_samyar mirbeygy.csv')   \n",
        "#print (A218)\n",
        "A218=np.array(A218)\n",
        "A218 = np.vstack(A218[:, :]).astype(np.float)\n",
        "#print (A218)\n",
        "x218time= A218[:,0]\n",
        "y218ac=[A218[:,1], A218[:,2], A218[:,3]] #ac_x, ac_y, ac_z\n",
        "y218encoder= [A218[:,4],A218[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x218time, y218ac[0],89 ,0) #see the signal before denoising\n",
        "dy218ac_x=wavelet_denoising(y218ac[0])\n",
        "dy218ac_y=wavelet_denoising(y218ac[1])\n",
        "dy218ac_z=wavelet_denoising(y218ac[2])\n",
        "#plot1ac(x218time, y218ac[0], 218, 0)\n",
        "#plot1ac(x218time, dy218ac_x, 218, 1)\n",
        "F218=alltop5points(dy218ac_x, dy218ac_y, dy218ac_z, x218time) #feature vector=FV\n",
        "F218=np.concatenate((F218,allenergy(dy218ac_x, dy218ac_y, dy218ac_z))) #add energy to FV\n",
        "F218=np.concatenate((F218,correlation(dy218ac_x, dy218ac_y, dy218ac_z))) #add correlation coefficients to FV\n",
        "F218=np.append(F218,[jolt(dy218ac_x, '218')])#add jolt to FV\n",
        "F218=np.append(F218,[3]) #4\n",
        "F218=np.append(F218,[jolt(dy218ac_y, '218')])#add jolt to FV\n",
        "F218=np.append(F218,[7])\n",
        "F218=np.append(F218,[x218time[len(x218time)-1]])\n",
        "y218encoder=np.array(y218encoder)\n",
        "newen=np.diff(y218encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F218=np.append(F218,[np.sum(newen)]) #add total number of turns\n",
        "F218=np.append(F218,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F218=np.append(F218,[len(newen[newen > 0])/x218time[len(x218time)-1]])\n",
        "F218=np.append(F218,[1,218]) #label autistic\n",
        "F218=np.append(F218,[jolt(dy218ac_z, '218')])#add jolt to FV\n",
        "F218=np.append(F218,[7])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwJBpjV8beli"
      },
      "outputs": [],
      "source": [
        "print('label 301')\n",
        "A301 = pd.read_csv(r'C:\\PythonCode\\N_Ala movahednia.csv')   \n",
        "#print (A301)\n",
        "A301=np.array(A301)\n",
        "A301 = np.vstack(A301[:, :]).astype(np.float)\n",
        "#print (A301)\n",
        "x301time= A301[:,0]\n",
        "y301ac=[A301[:,1], A301[:,2], A301[:,3]] #ac_x, ac_y, ac_z\n",
        "y301encoder= [A301[:,4],A301[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x301time, y301ac[0],89 ,0) #see the signal before denoising\n",
        "dy301ac_x=wavelet_denoising(y301ac[0])\n",
        "dy301ac_y=wavelet_denoising(y301ac[1])\n",
        "dy301ac_z=wavelet_denoising(y301ac[2])\n",
        "#plot1ac(x301time, y301ac[0], 301, 0)\n",
        "#plot1ac(x301time, dy301ac_x, 301, 1)\n",
        "F301=alltop5points(dy301ac_x, dy301ac_y, dy301ac_z, x301time) #feature vector=FV\n",
        "F301=np.concatenate((F301,allenergy(dy301ac_x, dy301ac_y, dy301ac_z))) #add energy to FV\n",
        "F301=np.concatenate((F301,correlation(dy301ac_x, dy301ac_y, dy301ac_z))) #add correlation coefficients to FV\n",
        "F301=np.append(F301,[jolt(dy301ac_x, '301')])#add jolt to FV\n",
        "F301=np.append(F301,[5])\n",
        "F301=np.append(F301,[jolt(dy301ac_y, '301')])#add jolt to FV\n",
        "F301=np.append(F301,[12])\n",
        "F301=np.append(F301,[x301time[len(x301time)-1]])\n",
        "y301encoder=np.array(y301encoder)\n",
        "newen=np.diff(y301encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F301=np.append(F301,[np.sum(newen)]) #add total number of turns\n",
        "F301=np.append(F301,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F301=np.append(F301,[len(newen[newen > 0])/x301time[len(x301time)-1]])\n",
        "F301=np.append(F301,[0,301]) #label normal\n",
        "F301=np.append(F301,[jolt(dy301ac_z, '301')])#add jolt to FV\n",
        "F301=np.append(F301,[12])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfCzfMy_bhM_"
      },
      "outputs": [],
      "source": [
        "print('label 302')\n",
        "A302 = pd.read_csv(r'C:\\PythonCode\\N_Ali adibzadeh.csv')   \n",
        "#print (A302)\n",
        "A302=np.array(A302)\n",
        "A302 = np.vstack(A302[:, :]).astype(np.float)\n",
        "#print (A302)\n",
        "x302time= A302[:,0]\n",
        "y302ac=[A302[:,1], A302[:,2], A302[:,3]] #ac_x, ac_y, ac_z\n",
        "y302encoder= [A302[:,4],A302[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x302time, y302ac[0],89 ,0) #see the signal before denoising\n",
        "dy302ac_x=wavelet_denoising(y302ac[0])\n",
        "dy302ac_y=wavelet_denoising(y302ac[1])\n",
        "dy302ac_z=wavelet_denoising(y302ac[2])\n",
        "#plot1ac(x302time, y302ac[0], 302, 0)\n",
        "#plot1ac(x302time, dy302ac_x, 302, 1)\n",
        "F302=alltop5points(dy302ac_x, dy302ac_y, dy302ac_z, x302time) #feature vector=FV\n",
        "F302=np.concatenate((F302,allenergy(dy302ac_x, dy302ac_y, dy302ac_z))) #add energy to FV\n",
        "F302=np.concatenate((F302,correlation(dy302ac_x, dy302ac_y, dy302ac_z))) #add correlation coefficients to FV\n",
        "F302=np.append(F302,[jolt(dy302ac_x, '302')])#add jolt to FV\n",
        "F302=np.append(F302,[7])\n",
        "F302=np.append(F302,[jolt(dy302ac_y, '302')])#add jolt to FV\n",
        "F302=np.append(F302,[14])\n",
        "F302=np.append(F302,[x302time[len(x302time)-1]])\n",
        "y302encoder=np.array(y302encoder)\n",
        "newen=np.diff(y302encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F302=np.append(F302,[np.sum(newen)]) #add total number of turns\n",
        "F302=np.append(F302,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F302=np.append(F302,[len(newen[newen > 0])/x302time[len(x302time)-1]])\n",
        "F302=np.append(F302,[0,302]) #label normal\n",
        "F302=np.append(F302,[jolt(dy302ac_z, '302')])#add jolt to FV\n",
        "F302=np.append(F302,[14])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_7bYSq9blB2"
      },
      "outputs": [],
      "source": [
        "print('label 303')\n",
        "A303 = pd.read_csv(r'C:\\PythonCode\\N_alireza tanha.csv')   \n",
        "#print (A303)\n",
        "A303=np.array(A303)\n",
        "A303 = np.vstack(A303[:, :]).astype(np.float)\n",
        "#print (A303)\n",
        "x303time= A303[:,0]\n",
        "y303ac=[A303[:,1], A303[:,2], A303[:,3]] #ac_x, ac_y, ac_z\n",
        "y303encoder= [A303[:,4],A303[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x303time, y303ac[0],89 ,0) #see the signal before denoising\n",
        "dy303ac_x=wavelet_denoising(y303ac[0])\n",
        "dy303ac_y=wavelet_denoising(y303ac[1])\n",
        "dy303ac_z=wavelet_denoising(y303ac[2])\n",
        "#plot1ac(x303time, y303ac[0], 303, 0)\n",
        "#plot1ac(x303time, dy303ac_x, 303, 1)\n",
        "F303=alltop5points(dy303ac_x, dy303ac_y, dy303ac_z, x303time) #feature vector=FV\n",
        "F303=np.concatenate((F303,allenergy(dy303ac_x, dy303ac_y, dy303ac_z))) #add energy to FV\n",
        "F303=np.concatenate((F303,correlation(dy303ac_x, dy303ac_y, dy303ac_z))) #add correlation coefficients to FV\n",
        "F303=np.append(F303,[jolt(dy303ac_x, '303')])#add jolt to FV\n",
        "F303=np.append(F303,[4]) #3\n",
        "F303=np.append(F303,[jolt(dy303ac_y, '303')])#add jolt to FV\n",
        "F303=np.append(F303,[2])\n",
        "F303=np.append(F303,[x303time[len(x303time)-1]])\n",
        "y303encoder=np.array(y303encoder)\n",
        "newen=np.diff(y303encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F303=np.append(F303,[np.sum(newen)]) #add total number of turns\n",
        "F303=np.append(F303,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F303=np.append(F303,[len(newen[newen > 0])/x303time[len(x303time)-1]])\n",
        "F303=np.append(F303,[0,303]) #label normal\n",
        "F303=np.append(F303,[jolt(dy303ac_z, '303')])#add jolt to FV\n",
        "F303=np.append(F303,[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbEEr_0_bnWW"
      },
      "outputs": [],
      "source": [
        "print('label 304')\n",
        "A304 = pd.read_csv(r'C:\\PythonCode\\N_amirhossein ghafarpour.csv')   \n",
        "#print (A304)\n",
        "A304=np.array(A304)\n",
        "A304 = np.vstack(A304[:, :]).astype(np.float)\n",
        "#print (A304)\n",
        "x304time= A304[:,0]\n",
        "y304ac=[A304[:,1], A304[:,2], A304[:,3]] #ac_x, ac_y, ac_z\n",
        "y304encoder= [A304[:,4],A304[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x304time, y304ac[0],89 ,0) #see the signal before denoising\n",
        "dy304ac_x=wavelet_denoising(y304ac[0])\n",
        "dy304ac_y=wavelet_denoising(y304ac[1])\n",
        "dy304ac_z=wavelet_denoising(y304ac[2])\n",
        "#plot1ac(x304time, y304ac[0], 304, 0)\n",
        "#plot1ac(x304time, dy304ac_x, 304, 1)\n",
        "F304=alltop5points(dy304ac_x, dy304ac_y, dy304ac_z, x304time) #feature vector=FV\n",
        "F304=np.concatenate((F304,allenergy(dy304ac_x, dy304ac_y, dy304ac_z))) #add energy to FV\n",
        "F304=np.concatenate((F304,correlation(dy304ac_x, dy304ac_y, dy304ac_z))) #add correlation coefficients to FV\n",
        "F304=np.append(F304,[jolt(dy304ac_x, '304')])#add jolt to FV\n",
        "F304=np.append(F304,[3])\n",
        "F304=np.append(F304,[jolt(dy304ac_y, '304')])#add jolt to FV\n",
        "F304=np.append(F304,[3]) #3\n",
        "F304=np.append(F304,[x304time[len(x304time)-1]])\n",
        "y304encoder=np.array(y304encoder)\n",
        "newen=np.diff(y304encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F304=np.append(F304,[np.sum(newen)]) #add total number of turns\n",
        "F304=np.append(F304,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F304=np.append(F304,[len(newen[newen > 0])/x304time[len(x304time)-1]])\n",
        "F304=np.append(F304,[0,304]) #label normal\n",
        "F304=np.append(F304,[jolt(dy304ac_z, '304')])#add jolt to FV\n",
        "F304=np.append(F304,[3]) #3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syJerP3AbptA"
      },
      "outputs": [],
      "source": [
        "print('label 305')\n",
        "A305 = pd.read_csv(r'C:\\PythonCode\\N_bahar erfanian.csv')   \n",
        "#print (A305)\n",
        "A305=np.array(A305)\n",
        "A305 = np.vstack(A305[:, :]).astype(np.float)\n",
        "#print (A305)\n",
        "x305time= A305[:,0]\n",
        "y305ac=[A305[:,1], A305[:,2], A305[:,3]] #ac_x, ac_y, ac_z\n",
        "y305encoder= [A305[:,4],A305[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x305time, y305ac[0],89 ,0) #see the signal before denoising\n",
        "dy305ac_x=wavelet_denoising(y305ac[0])\n",
        "dy305ac_y=wavelet_denoising(y305ac[1])\n",
        "dy305ac_z=wavelet_denoising(y305ac[2])\n",
        "#plot1ac(x305time, y305ac[0], 305, 0)\n",
        "#plot1ac(x305time, dy305ac_x, 305, 1)\n",
        "F305=alltop5points(dy305ac_x, dy305ac_y, dy305ac_z, x305time) #feature vector=FV\n",
        "F305=np.concatenate((F305,allenergy(dy305ac_x, dy305ac_y, dy305ac_z))) #add energy to FV\n",
        "F305=np.concatenate((F305,correlation(dy305ac_x, dy305ac_y, dy305ac_z))) #add correlation coefficients to FV\n",
        "F305=np.append(F305,[jolt(dy305ac_x, '305')])#add jolt to FV\n",
        "F305=np.append(F305,[7]) #8\n",
        "F305=np.append(F305,[jolt(dy305ac_y, '305')])#add jolt to FV\n",
        "F305=np.append(F305,[14])\n",
        "F305=np.append(F305,[x305time[len(x305time)-1]])\n",
        "y305encoder=np.array(y305encoder)\n",
        "newen=np.diff(y305encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F305=np.append(F305,[np.sum(newen)]) #add total number of turns\n",
        "F305=np.append(F305,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F305=np.append(F305,[len(newen[newen > 0])/x305time[len(x305time)-1]])\n",
        "F305=np.append(F305,[0,305]) #label normal\n",
        "F305=np.append(F305,[jolt(dy305ac_z, '305')])#add jolt to FV\n",
        "F305=np.append(F305,[14])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeKK6ie-bsOc"
      },
      "outputs": [],
      "source": [
        "print('label 306')\n",
        "A306 = pd.read_csv(r'C:\\PythonCode\\N_dorsa ebrahimi.csv')   \n",
        "#print (A306)\n",
        "A306=np.array(A306)\n",
        "A306 = np.vstack(A306[:, :]).astype(np.float)\n",
        "#print (A306)\n",
        "x306time= A306[:,0]\n",
        "y306ac=[A306[:,1], A306[:,2], A306[:,3]] #ac_x, ac_y, ac_z\n",
        "y306encoder= [A306[:,4],A306[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x306time, y306ac[0],89 ,0) #see the signal before denoising\n",
        "dy306ac_x=wavelet_denoising(y306ac[0])\n",
        "dy306ac_y=wavelet_denoising(y306ac[1])\n",
        "dy306ac_z=wavelet_denoising(y306ac[2])\n",
        "#plot1ac(x306time, y306ac[0], 306, 0)\n",
        "#plot1ac(x306time, dy306ac_x, 306, 1)\n",
        "F306=alltop5points(dy306ac_x, dy306ac_y, dy306ac_z, x306time) #feature vector=FV\n",
        "F306=np.concatenate((F306,allenergy(dy306ac_x, dy306ac_y, dy306ac_z))) #add energy to FV\n",
        "F306=np.concatenate((F306,correlation(dy306ac_x, dy306ac_y, dy306ac_z))) #add correlation coefficients to FV\n",
        "F306=np.append(F306,[jolt(dy306ac_x, '306')])#add jolt to FV\n",
        "F306=np.append(F306,[5])\n",
        "F306=np.append(F306,[jolt(dy306ac_y, '306')])#add jolt to FV\n",
        "F306=np.append(F306,[7])\n",
        "F306=np.append(F306,[x306time[len(x306time)-1]])\n",
        "y306encoder=np.array(y306encoder)\n",
        "newen=np.diff(y306encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F306=np.append(F306,[np.sum(newen)]) #add total number of turns\n",
        "F306=np.append(F306,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F306=np.append(F306,[len(newen[newen > 0])/x306time[len(x306time)-1]])\n",
        "F306=np.append(F306,[0,306]) #label normal\n",
        "F306=np.append(F306,[jolt(dy306ac_z, '306')])#add jolt to FV\n",
        "F306=np.append(F306,[7])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9o-z22-bvNR"
      },
      "outputs": [],
      "source": [
        "print('label 307')\n",
        "A307 = pd.read_csv(r'C:\\PythonCode\\N_fatemeh sadat falah.csv')   \n",
        "#print (A307)\n",
        "A307=np.array(A307)\n",
        "A307 = np.vstack(A307[:, :]).astype(np.float)\n",
        "#print (A307)\n",
        "x307time= A307[:,0]\n",
        "y307ac=[A307[:,1], A307[:,2], A307[:,3]] #ac_x, ac_y, ac_z\n",
        "y307encoder= [A307[:,4],A307[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x307time, y307ac[0],89 ,0) #see the signal before denoising\n",
        "dy307ac_x=wavelet_denoising(y307ac[0])\n",
        "dy307ac_y=wavelet_denoising(y307ac[1])\n",
        "dy307ac_z=wavelet_denoising(y307ac[2])\n",
        "#plot1ac(x307time, y307ac[0], 307, 0)\n",
        "#plot1ac(x307time, dy307ac_x, 307, 1)\n",
        "F307=alltop5points(dy307ac_x, dy307ac_y, dy307ac_z, x307time) #feature vector=FV\n",
        "F307=np.concatenate((F307,allenergy(dy307ac_x, dy307ac_y, dy307ac_z))) #add energy to FV\n",
        "F307=np.concatenate((F307,correlation(dy307ac_x, dy307ac_y, dy307ac_z))) #add correlation coefficients to FV\n",
        "F307=np.append(F307,[jolt(dy307ac_x, '307')])#add jolt to FV\n",
        "F307=np.append(F307,[7])\n",
        "F307=np.append(F307,[jolt(dy307ac_y, '307')])#add jolt to FV\n",
        "F307=np.append(F307,[8])\n",
        "F307=np.append(F307,[x307time[len(x307time)-1]])\n",
        "y307encoder=np.array(y307encoder)\n",
        "newen=np.diff(y307encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F307=np.append(F307,[np.sum(newen)]) #add total number of turns\n",
        "F307=np.append(F307,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F307=np.append(F307,[len(newen[newen > 0])/x307time[len(x307time)-1]])\n",
        "F307=np.append(F307,[0,307]) #label normal\n",
        "F307=np.append(F307,[jolt(dy307ac_z, '307')])#add jolt to FV\n",
        "F307=np.append(F307,[8])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHq9tpTobxdr"
      },
      "outputs": [],
      "source": [
        "print('label 308')\n",
        "A308 = pd.read_csv(r'C:\\PythonCode\\N_hosein aminian.csv')   \n",
        "#print (A308)\n",
        "A308=np.array(A308)\n",
        "A308 = np.vstack(A308[:, :]).astype(np.float)\n",
        "#print (A308)\n",
        "x308time= A308[:,0]\n",
        "y308ac=[A308[:,1], A308[:,2], A308[:,3]] #ac_x, ac_y, ac_z\n",
        "y308encoder= [A308[:,4],A308[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x308time, y308ac[0],89 ,0) #see the signal before denoising\n",
        "dy308ac_x=wavelet_denoising(y308ac[0])\n",
        "dy308ac_y=wavelet_denoising(y308ac[1])\n",
        "dy308ac_z=wavelet_denoising(y308ac[2])\n",
        "#plot1ac(x308time, y308ac[0], 308, 0)\n",
        "#plot1ac(x308time, dy308ac_x, 308, 1)\n",
        "F308=alltop5points(dy308ac_x, dy308ac_y, dy308ac_z, x308time) #feature vector=FV\n",
        "F308=np.concatenate((F308,allenergy(dy308ac_x, dy308ac_y, dy308ac_z))) #add energy to FV\n",
        "F308=np.concatenate((F308,correlation(dy308ac_x, dy308ac_y, dy308ac_z))) #add correlation coefficients to FV\n",
        "F308=np.append(F308,[jolt(dy308ac_x, '308')])#add jolt to FV\n",
        "F308=np.append(F308,[4]) #7\n",
        "F308=np.append(F308,[jolt(dy308ac_y, '308')])#add jolt to FV\n",
        "F308=np.append(F308,[5])\n",
        "F308=np.append(F308,[x308time[len(x308time)-1]])\n",
        "y308encoder=np.array(y308encoder)\n",
        "newen=np.diff(y308encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F308=np.append(F308,[np.sum(newen)]) #add total number of turns\n",
        "F308=np.append(F308,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F308=np.append(F308,[len(newen[newen > 0])/x308time[len(x308time)-1]])\n",
        "F308=np.append(F308,[0,308]) #label normal\n",
        "F308=np.append(F308,[jolt(dy308ac_z, '308')])#add jolt to FV\n",
        "F308=np.append(F308,[5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyI3Zj61bzTU"
      },
      "outputs": [],
      "source": [
        "print('label 309')\n",
        "A309 = pd.read_csv(r'C:\\PythonCode\\N_hosna golshenas.csv')   \n",
        "#print (A309)\n",
        "A309=np.array(A309)\n",
        "A309 = np.vstack(A309[:, :]).astype(np.float)\n",
        "#print (A309)\n",
        "x309time= A309[:,0]\n",
        "y309ac=[A309[:,1], A309[:,2], A309[:,3]] #ac_x, ac_y, ac_z\n",
        "y309encoder= [A309[:,4],A309[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x309time, y309ac[0],89 ,0) #see the signal before denoising\n",
        "dy309ac_x=wavelet_denoising(y309ac[0])\n",
        "dy309ac_y=wavelet_denoising(y309ac[1])\n",
        "dy309ac_z=wavelet_denoising(y309ac[2])\n",
        "#plot1ac(x309time, y309ac[0], 309, 0)\n",
        "#plot1ac(x309time, dy309ac_x, 309, 1)\n",
        "F309=alltop5points(dy309ac_x, dy309ac_y, dy309ac_z, x309time) #feature vector=FV\n",
        "F309=np.concatenate((F309,allenergy(dy309ac_x, dy309ac_y, dy309ac_z))) #add energy to FV\n",
        "F309=np.concatenate((F309,correlation(dy309ac_x, dy309ac_y, dy309ac_z))) #add correlation coefficients to FV\n",
        "F309=np.append(F309,[jolt(dy309ac_x, '309')])#add jolt to FV\n",
        "F309=np.append(F309,[4]) #5\n",
        "F309=np.append(F309,[jolt(dy309ac_y, '309')])#add jolt to FV\n",
        "F309=np.append(F309,[13])\n",
        "F309=np.append(F309,[x309time[len(x309time)-1]])\n",
        "y309encoder=np.array(y309encoder)\n",
        "newen=np.diff(y309encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F309=np.append(F309,[np.sum(newen)]) #add total number of turns\n",
        "F309=np.append(F309,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F309=np.append(F309,[len(newen[newen > 0])/x309time[len(x309time)-1]])\n",
        "F309=np.append(F309,[0,309]) #label normal\n",
        "F309=np.append(F309,[jolt(dy309ac_z, '309')])#add jolt to FV\n",
        "F309=np.append(F309,[13])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzPa7WCeb20G"
      },
      "outputs": [],
      "source": [
        "print('label 310')\n",
        "A310 = pd.read_csv(r'C:\\PythonCode\\N_hosna karimi.csv')   \n",
        "#print (A310)\n",
        "A310=np.array(A310)\n",
        "A310 = np.vstack(A310[:, :]).astype(np.float)\n",
        "#print (A310)\n",
        "x310time= A310[:,0]\n",
        "y310ac=[A310[:,1], A310[:,2], A310[:,3]] #ac_x, ac_y, ac_z\n",
        "y310encoder= [A310[:,4],A310[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x310time, y310ac[0],89 ,0) #see the signal before denoising\n",
        "dy310ac_x=wavelet_denoising(y310ac[0])\n",
        "dy310ac_y=wavelet_denoising(y310ac[1])\n",
        "dy310ac_z=wavelet_denoising(y310ac[2])\n",
        "#plot1ac(x310time, y310ac[0], 310, 0)\n",
        "#plot1ac(x310time, dy310ac_x, 310, 1)\n",
        "F310=alltop5points(dy310ac_x, dy310ac_y, dy310ac_z, x310time) #feature vector=FV\n",
        "F310=np.concatenate((F310,allenergy(dy310ac_x, dy310ac_y, dy310ac_z))) #add energy to FV\n",
        "F310=np.concatenate((F310,correlation(dy310ac_x, dy310ac_y, dy310ac_z))) #add correlation coefficients to FV\n",
        "F310=np.append(F310,[jolt(dy310ac_x, '310')])#add jolt to FV\n",
        "F310=np.append(F310,[3])\n",
        "F310=np.append(F310,[jolt(dy310ac_y, '310')])#add jolt to FV\n",
        "F310=np.append(F310,[3])\n",
        "F310=np.append(F310,[x310time[len(x310time)-1]])\n",
        "y310encoder=np.array(y310encoder)\n",
        "newen=np.diff(y310encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F310=np.append(F310,[np.sum(newen)]) #add total number of turns\n",
        "F310=np.append(F310,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F310=np.append(F310,[len(newen[newen > 0])/x310time[len(x310time)-1]])\n",
        "F310=np.append(F310,[0,310]) #label normal\n",
        "F310=np.append(F310,[jolt(dy310ac_z, '310')])#add jolt to FV\n",
        "F310=np.append(F310,[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFeFnQISb5Fu"
      },
      "outputs": [],
      "source": [
        "print('label 311')\n",
        "A311 = pd.read_csv(r'C:\\PythonCode\\N_mohammad amin salem.csv')   \n",
        "#print (A311)\n",
        "A311=np.array(A311)\n",
        "A311 = np.vstack(A311[:, :]).astype(np.float)\n",
        "#print (A311)\n",
        "x311time= A311[:,0]\n",
        "y311ac=[A311[:,1], A311[:,2], A311[:,3]] #ac_x, ac_y, ac_z\n",
        "y311encoder= [A311[:,4],A311[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x311time, y311ac[0],89 ,0) #see the signal before denoising\n",
        "dy311ac_x=wavelet_denoising(y311ac[0])\n",
        "dy311ac_y=wavelet_denoising(y311ac[1])\n",
        "dy311ac_z=wavelet_denoising(y311ac[2])\n",
        "#plot1ac(x311time, y311ac[0], 311, 0)\n",
        "#plot1ac(x311time, dy311ac_x, 311, 1)\n",
        "F311=alltop5points(dy311ac_x, dy311ac_y, dy311ac_z, x311time) #feature vector=FV\n",
        "F311=np.concatenate((F311,allenergy(dy311ac_x, dy311ac_y, dy311ac_z))) #add energy to FV\n",
        "F311=np.concatenate((F311,correlation(dy311ac_x, dy311ac_y, dy311ac_z))) #add correlation coefficients to FV\n",
        "F311=np.append(F311,[jolt(dy311ac_x, '311')])#add jolt to FV\n",
        "F311=np.append(F311,[2])\n",
        "F311=np.append(F311,[jolt(dy311ac_y, '311')])#add jolt to FV\n",
        "F311=np.append(F311,[2])\n",
        "F311=np.append(F311,[x311time[len(x311time)-1]])\n",
        "y311encoder=np.array(y311encoder)\n",
        "newen=np.diff(y311encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F311=np.append(F311,[np.sum(newen)]) #add total number of turns\n",
        "F311=np.append(F311,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F311=np.append(F311,[len(newen[newen > 0])/x311time[len(x311time)-1]])\n",
        "F311=np.append(F311,[0,311]) #label normal\n",
        "F311=np.append(F311,[jolt(dy311ac_z, '311')])#add jolt to FV\n",
        "F311=np.append(F311,[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDyYHADCb7GO"
      },
      "outputs": [],
      "source": [
        "print('label 312')\n",
        "A312 = pd.read_csv(r'C:\\PythonCode\\N_mohammad amir ghobadi.csv')   \n",
        "#print (A312)\n",
        "A312=np.array(A312)\n",
        "A312 = np.vstack(A312[:, :]).astype(np.float)\n",
        "#print (A312)\n",
        "x312time= A312[:,0]\n",
        "y312ac=[A312[:,1], A312[:,2], A312[:,3]] #ac_x, ac_y, ac_z\n",
        "y312encoder= [A312[:,4],A312[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x312time, y312ac[0],89 ,0) #see the signal before denoising\n",
        "dy312ac_x=wavelet_denoising(y312ac[0])\n",
        "dy312ac_y=wavelet_denoising(y312ac[1])\n",
        "dy312ac_z=wavelet_denoising(y312ac[2])\n",
        "#plot1ac(x312time, y312ac[0], 312, 0)\n",
        "#plot1ac(x312time, dy312ac_x, 312, 1)\n",
        "F312=alltop5points(dy312ac_x, dy312ac_y, dy312ac_z, x312time) #feature vector=FV\n",
        "F312=np.concatenate((F312,allenergy(dy312ac_x, dy312ac_y, dy312ac_z))) #add energy to FV\n",
        "F312=np.concatenate((F312,correlation(dy312ac_x, dy312ac_y, dy312ac_z))) #add correlation coefficients to FV\n",
        "F312=np.append(F312,[jolt(dy312ac_x, '312')])#add jolt to FV\n",
        "F312=np.append(F312,[7]) #6\n",
        "F312=np.append(F312,[jolt(dy312ac_y, '312')])#add jolt to FV\n",
        "F312=np.append(F312,[3]) \n",
        "F312=np.append(F312,[x312time[len(x312time)-1]])\n",
        "y312encoder=np.array(y312encoder)\n",
        "newen=np.diff(y312encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F312=np.append(F312,[np.sum(newen)]) #add total number of turns\n",
        "F312=np.append(F312,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F312=np.append(F312,[len(newen[newen > 0])/x312time[len(x312time)-1]])\n",
        "F312=np.append(F312,[0,312]) #label normal\n",
        "F312=np.append(F312,[jolt(dy312ac_z, '312')])#add jolt to FV\n",
        "F312=np.append(F312,[3]) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPfSQPYvb82U"
      },
      "outputs": [],
      "source": [
        "print('label 313')\n",
        "A313 = pd.read_csv(r'C:\\PythonCode\\N_mohammad sadra khayami.csv')   \n",
        "#print (A313)\n",
        "A313=np.array(A313)\n",
        "A313 = np.vstack(A313[:, :]).astype(np.float)\n",
        "#print (A313)\n",
        "x313time= A313[:,0]\n",
        "y313ac=[A313[:,1], A313[:,2], A313[:,3]] #ac_x, ac_y, ac_z\n",
        "y313encoder= [A313[:,4],A313[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x313time, y313ac[0],89 ,0) #see the signal before denoising\n",
        "dy313ac_x=wavelet_denoising(y313ac[0])\n",
        "dy313ac_y=wavelet_denoising(y313ac[1])\n",
        "dy313ac_z=wavelet_denoising(y313ac[2])\n",
        "#plot1ac(x313time, y313ac[0], 313, 0)\n",
        "#plot1ac(x313time, dy313ac_x, 313, 1)\n",
        "F313=alltop5points(dy313ac_x, dy313ac_y, dy313ac_z, x313time) #feature vector=FV\n",
        "F313=np.concatenate((F313,allenergy(dy313ac_x, dy313ac_y, dy313ac_z))) #add energy to FV\n",
        "F313=np.concatenate((F313,correlation(dy313ac_x, dy313ac_y, dy313ac_z))) #add correlation coefficients to FV\n",
        "F313=np.append(F313,[jolt(dy313ac_x, '313')])#add x jolt to FV\n",
        "F313=np.append(F313,[8]) #9\n",
        "F313=np.append(F313,[jolt(dy313ac_y, '313')])#add y jolt to FV\n",
        "F313=np.append(F313,[7])\n",
        "F313=np.append(F313,[x313time[len(x313time)-1]])\n",
        "y313encoder=np.array(y313encoder)\n",
        "newen=np.diff(y313encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F313=np.append(F313,[np.sum(newen)]) #add total number of turns\n",
        "F313=np.append(F313,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F313=np.append(F313,[len(newen[newen > 0])/x313time[len(x313time)-1]])\n",
        "F313=np.append(F313,[0,313]) #label normal\n",
        "F313=np.append(F313,[jolt(dy313ac_z, '313')])#add y jolt to FV\n",
        "F313=np.append(F313,[7])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByHL7zQNb_Ko"
      },
      "outputs": [],
      "source": [
        "print('label 314')\n",
        "A314 = pd.read_csv(r'C:\\PythonCode\\N_sobhan aghamohammad.csv')   \n",
        "#print (A314)\n",
        "A314=np.array(A314)\n",
        "A314 = np.vstack(A314[:, :]).astype(np.float)\n",
        "#print (A314)\n",
        "x314time= A314[:,0]\n",
        "y314ac=[A314[:,1], A314[:,2], A314[:,3]] #ac_x, ac_y, ac_z\n",
        "y314encoder= [A314[:,4],A314[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x314time, y314ac[0],89 ,0) #see the signal before denoising\n",
        "dy314ac_x=wavelet_denoising(y314ac[0])\n",
        "dy314ac_y=wavelet_denoising(y314ac[1])\n",
        "dy314ac_z=wavelet_denoising(y314ac[2])\n",
        "#plot1ac(x314time, y314ac[0], 314, 0)\n",
        "#plot1ac(x314time, dy314ac_x, 314, 1)\n",
        "F314=alltop5points(dy314ac_x, dy314ac_y, dy314ac_z, x314time) #feature vector=FV\n",
        "F314=np.concatenate((F314,allenergy(dy314ac_x, dy314ac_y, dy314ac_z))) #add energy to FV\n",
        "F314=np.concatenate((F314,correlation(dy314ac_x, dy314ac_y, dy314ac_z))) #add correlation coefficients to FV\n",
        "F314=np.append(F314,[jolt(dy314ac_x, '314')])#add jolt to FV\n",
        "F314=np.append(F314,[1])\n",
        "F314=np.append(F314,[jolt(dy314ac_y, '314')])#add jolt to FV\n",
        "F314=np.append(F314,[3])\n",
        "F314=np.append(F314,[x314time[len(x314time)-1]])\n",
        "y314encoder=np.array(y314encoder)\n",
        "newen=np.diff(y314encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F314=np.append(F314,[np.sum(newen)]) #add total number of turns\n",
        "F314=np.append(F314,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F314=np.append(F314,[len(newen[newen > 0])/x314time[len(x314time)-1]])\n",
        "F314=np.append(F314,[0,314]) #label normal\n",
        "F314=np.append(F314,[jolt(dy314ac_z, '314')])#add jolt to FV\n",
        "F314=np.append(F314,[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf2ScSKVcAli"
      },
      "outputs": [],
      "source": [
        "print('label 315')\n",
        "A315 = pd.read_csv(r'C:\\PythonCode\\N_zahra tavakoli.csv')   \n",
        "#print (A315)\n",
        "A315=np.array(A315)\n",
        "A315 = np.vstack(A315[:, :]).astype(np.float)\n",
        "#print (A315)\n",
        "x315time= A315[:,0]\n",
        "y315ac=[A315[:,1], A315[:,2], A315[:,3]] #ac_x, ac_y, ac_z\n",
        "y315encoder= [A315[:,4],A315[:,5]]  #encoder1, encoder2\n",
        "plot1ac(x315time, y315ac[0],89 ,0) #see the signal before denoising\n",
        "dy315ac_x=wavelet_denoising(y315ac[0])\n",
        "dy315ac_y=wavelet_denoising(y315ac[1])\n",
        "dy315ac_z=wavelet_denoising(y315ac[2])\n",
        "#plot1ac(x315time, y315ac[0], 315, 0)\n",
        "#plot1ac(x315time, dy315ac_x, 315, 1)\n",
        "F315=alltop5points(dy315ac_x, dy315ac_y, dy315ac_z, x315time) #feature vector=FV\n",
        "F315=np.concatenate((F315,allenergy(dy315ac_x, dy315ac_y, dy315ac_z))) #add energy to FV\n",
        "F315=np.concatenate((F315,correlation(dy315ac_x, dy315ac_y, dy315ac_z))) #add correlation coefficients to FV\n",
        "F315=np.append(F315,[jolt(dy315ac_x, '315')])#add jolt to FV\n",
        "F315=np.append(F315,[4]) #5\n",
        "F315=np.append(F315,[jolt(dy315ac_y, '315')])#add jolt to FV\n",
        "F315=np.append(F315,[9]) #5\n",
        "F315=np.append(F315,[x315time[len(x315time)-1]])\n",
        "y315encoder=np.array(y315encoder)\n",
        "newen=np.diff(y315encoder)\n",
        "newen=np.where(newen>10, 0, newen)\n",
        "F315=np.append(F315,[np.sum(newen)]) #add total number of turns\n",
        "F315=np.append(F315,[len(newen[newen > 0])]) #add number of chnages in encoder\n",
        "F315=np.append(F315,[len(newen[newen > 0])/x315time[len(x315time)-1]])\n",
        "F315=np.append(F315,[0,315]) #label normal\n",
        "F315=np.append(F315,[jolt(dy315ac_z, '315')])#add jolt to FV\n",
        "F315=np.append(F315,[9]) #5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzLMbYBvcD78"
      },
      "outputs": [],
      "source": [
        "# info=np.array([1 ,1 ,1 ,1 ,1 ,0,0,0,'NA108','NA120','NA121','NA124'])\n",
        "#info1=np.array(5*['fx']+5*['fy']+5*['fz']+5*['Ax']+5*['Ay']+5*['Az']+['Ex']+['Ey']+['Ez']+['Cxy']+['Cxz']+['Cyz']+['J'])\n",
        "#info2=np.array(['0','au95','au100','au106','au112','au118','no89','no94','no102','NA108','NA120','NA121','NA124'])\n",
        "Fautistic=np.concatenate((F95.reshape(1,46),F100.reshape(1,46),F106.reshape(1,46),F112.reshape(1,46),F118.reshape(1,46),F201.reshape(1,46),F202.reshape(1,46),F203.reshape(1,46),F204.reshape(1,46),F205.reshape(1,46),F206.reshape(1,46),F207.reshape(1,46),F208.reshape(1,46),F209.reshape(1,46),F210.reshape(1,46),F211.reshape(1,46),F212.reshape(1,46),F213.reshape(1,46),F214.reshape(1,46),F215.reshape(1,46),F216.reshape(1,46),F217.reshape(1,46),F218.reshape(1,46)))\n",
        "Fnormal=np.concatenate((F89.reshape(1,46),F94.reshape(1,46),F102.reshape(1,46),F301.reshape(1,46),F302.reshape(1,46),F303.reshape(1,46),F304.reshape(1,46),F305.reshape(1,46),F306.reshape(1,46),F307.reshape(1,46),F308.reshape(1,46),F309.reshape(1,46),F310.reshape(1,46),F311.reshape(1,46),F312.reshape(1,46),F313.reshape(1,46),F314.reshape(1,46),F315.reshape(1,46)))\n",
        "Fothers=np.concatenate((F108.reshape(1,46),F120.reshape(1,46),F121.reshape(1,46),F124.reshape(1,46)))\n",
        "#Ftotal=np.concatenate((info1.reshape(1,37),Fautistic,Fnormal,Fothers))\n",
        "Ftotal=np.concatenate((Fautistic,Fnormal,Fothers))\n",
        "Ftotal=np.transpose(Ftotal)\n",
        "#Ftotal=np.concatenate((info2.reshape(1,13),Ftotal))\n",
        "print('Ftotal')\n",
        "print(Ftotal)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "intelligent_toy_car.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
